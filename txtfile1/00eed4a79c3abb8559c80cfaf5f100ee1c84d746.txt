I. INTRODUCTION

We are facing, first hand, an abrupt and sudden change of the world as we knew because of the novel Coronavirus outbreak. Known as COVID-19, it first appeared in late December 2019 in Wuhan, China, and few months later, on This Project was partially supported by the Department of National Defence's Innovation for Defence Excellence and Security (IDEaS) program, Canada. Corresponding Author is Arash Mohammadi, email: arash.mohammadi@concordia.ca the 11 th of March 2020, was characterized as a pandemic by World Health Organization (WHO). Given its high contingency nature, relatively unknown behaviour, systemic complications, and adverse effects ranging from human fatalities to economic recessions across the world, it is of importance to develop efficient processing/learning models to help overcome this pandemic and be prepared for potential future ones. The Reverse-Transcription Polymerase Chain Reaction (RT-PCR) is the standard testing approach for early diagnosis of suspected cases of COVID-19. Unavailability of enough RT-PCR testing kits particularly in areas severely affected by the pandemic and its relatively high and variable falsenegative rate (i.e., highest during the first five days (up to 67%), and lowest on day 8 (21%) [2] ), resulted in focusing on medical image Radiomics [3] as a complementary source for diagnosis/prognosis.Recent studies [4] - [6] show that chest Computed Tomography (CT) scans and Chest Radiographs (CXR) reveal informative features of COVID-19 that can assist in the monitoring, severity assessment, and treatment of COVID-19 [13] . According to the guideline provided by WHO, use of chest imaging as a complementary source of data is recommended in different scenarios and stages of COVID-19 to assist radiologists and physicians to detect and evaluate the disease more accurately. CT and CXR can decrease the false negative rate both at the admission and discharge times. It is worth mentioning that chest CT has a key role for diagnosis of COVID-19 in the very early stages of the infection and also to set up a prognosis. Comparisons between CT and RT-PCR at early stages of COVID-19 infection show that CT abnormalities may appear before PCR positivity. In other words, CT has greater sensitivity during the early stages of the infection. In addition, false negatives in RT-PCR results occur both at the admission and discharge. Finally, CT plays its role over the course of the disease for evaluating changes in severity and for treatment adjustments. The key power of chest imaging is in its prognostic value to identify severity of the arXiv:2012.14106v1 [eess.IV] 28 Dec 2020 disease, likelihood of needing hospitalization and/or admission to Intensive Care Unit (ICU). However, interpretation of chest images for confirming the suspected cases of COVID-19, and severity assessment of the disease based on imaging findings are time-consuming and may be challenging.Interpretation of CT and CXR images should be performed by expert thoracic radiologists, who may not be easily accessible especially during the outbreak when the number of suspected cases of COVID-19 is growing up exponentially. To address these issues, there has been a surge of interest in developing Signal Processing (SP) and Deep Learning (DL) techniques to extract informative features from chest images and help in fast detection and risk assessment of the COVID-19 infection. We would like to mention that although research works on COVID-19-related topics have started very recently, the extensive number of research works that have been disseminated during this short period of time makes the topic mature. More specifically, extensive research works on application of Signal/Image Processing and Artificial Intelligence (AI) for COVID-19 have lead to almost 1, 200 publications by the end of November 2020. Fig. 1 presents COVID-19 research trend in year 2020, obtained from PubMed with the keyword "COVID-19" and either of the following keywords: "Signal Processing", "Machine Learning", "AI", or "Deep Learning". These publications cover several aspects and applications of SP/DL for COVID-19 including diagnosis, classification, detection, segmentation, severity assessment, and survival analysis.In summary, in this feature article, we aim to present an overview of the current state, challenges, and opportunities of developing SP/DL-empowered models for diagnosis and prognosis of the COVID-19 infection based on medical images. The article will mainly focus on the problems, applications and on how SP/DL models can be used to address the identified problems/applications. In brief, we will cover the following main topics:(i) We focus on SP techniques specific to COVID-19 images and target specialized SP aspects of COVID-19 diagnoses, including Analytic Epidemiology and Hypersignal Processing (HP) theory as advanced processing solutions of COVID-19. (ii) Introduction of potential applications of SP/DL-based models for the diagnosis and predictive prognosis of COVID-19 infections using medical images as the main source of data.(iii) Investigation of the required medical background related to COVID-19 for development of advanced SP/DL models. An overview of different characteristics of COVID-19 that can be observed on chest images is presented. Furthermore, we describe how these imaging findings are related to the severity of the disease, and how they can be utilized in the development of SP/DL models. (iv) Presentation of DL Radiomic directions specific to the analysis of COVID-19 infection. We focus on DLbased solutions from the following four different aspects: Segmentation of COVID-19 Lesions; Predictive models for outcome prediction in COVID-19 patients; DL/SP models for severity assessment, and; Diagnosis and classification of COVID-19 cases. (v) Introducing challenges, open problems, and opportunities of developing intelligent and autonomous models for diagnosis/prognosis of COVID-19.Distinction with Existing Articles: As a final note, we would like to briefly elaborate on the differences between this article and a recent feature article [3] on Radiomics and other survays/tutorials [4] - [6] on COVID-19. In particular, Reference [3] is focused on hand-crafted and deep learningbased techniques for extracting features from cancer-related images. Cancer diagnosis is essentially a completely different task than that of COVID-19 analysis, which requires its own specific techniques and solutions. For instance, while nodules have solid shapes and defined locations, COVID-19 infection areas could be multifocal, ill defined and diverse in pattern or (morphology). Therefore, the traditional Radiomics filters are not applicable to the latter. Furthermore, images from patients with pulmonary malignancies contain far less motion artifacts compared to COVID-19 ones, where patients suffer from dyspnea, calling for more advanced artifact reduction techniques. Deep learning models developed for Cancer Radiomics are also not transferable to COVID-19 without modifications. This is mainly due to the fact that in a patient with COVID-19 a large number of slices may be affected, for which 3D analysis and more powerful resources are required. With regards to differences with recent survay/tutorial articles on COVID-19 research, Reference [4] is limited to deep learning techniques. In this article, however, we also focus on SP modeling, applications, required medical background, and challenges/open-problems. Reference [5] is more focused on the medical background and imaging modalities and AI models are not discussed in a separate section compared to this article, where different models and applications are separated and discussed. Reference [6] reviews a subset of deep learning models, without referring to SP methods, and challenges. The reminder of the manuscript is organized as follows: Section II is devoted to analytic epidemiology and hypersignal processing for COVID-19. Applications and imaging modalities for diagnosis/prognosis of COVID-19 images are then presented in Section III. SL/DL-based Radiomic models specific to the analysis of COVID-19 infection are then described in Section IV covering the following four application domains: Segmentation of COVID-19 lesions; Predictive models for outcome prediction; Severity assessment, and; Diagno-and the set of lab tests be L = L 1 (N ucleicAcid), L 2 (SoreSample), L 3 (LungImage) .The diagnosis outcomes E of COVID-19 infections are detected by the Cartesian product between the sets of logical values of detection symptoms E S and lab confirmations E L as follows [13] :where T |L and F |L denotes a Boolean logical variable for True or False, respectively. The diagnosing results are classified in the categories of symptomatic positive, susceptibly positive, negative, and susceptibly negative. The big-R notation [14] , [15] is a generic calculus that denotes an iterative or recursive series of recurrent structures or embedded functions. Eq. (1) reveals that many important symptoms and diagnosis of COVID-19 are in the domain of advanced signal processing as a foundation for COVID-19 diagnosis. In analytic epidemiology, the reproductive ratio R 0 of a contagious disease is modeled as an exponential transmission series N inf (t) on the t 0 + kth day, which is estimated by a product of initial infectives N inf (t) and the average reproductive rate raised to the kth power:Therefore, the average reproductive rate of a pandemic transmission is reduced to the kth root of the average ratio between the number of infectives N inf (t 0 + k) cumulatively infected at t 0 + k by each initial infective N inf (t 0 ):For instance, WHO has empirically estimatedR 0 of COVID-19 in the range of 2.24 to 4.00 [9] , which was considerably higher than those obtained in rigorous analyses with real-world signals according to Eqs. (2) and (3) as rigorously treated a long series of pandemic signals.The reproductive rateR 0 in analytic epidemiology has been adopted as the key indicator θ for the congruous severity classified in two categories by the thresholdR 0 = 1.0, i.e.:However, when investigating into the nature of pandemic dynamics to rigorously predict the pandemic trends, we found that in order to model more general and complex pandemic dynamics, the reproductive rate must be treated as a series of variables R 0 (t) over time. This finding has led to the formal model of the series of dynamic reproductive rates of COVID-19, which is recursively determined by a long-chain of causal probabilities over time:Simulations performed based on real-world signals have provided highly accurate predications based on the mathematical model of the analytic epidemiology theory and its dynamic predictability for the pandemic signal series [13] .

B. Hypersignal Processing (HP) for COVID-19 Image Diagnoses

Hypersignals are a general structure of abstract or realworld signals beyond 1D or its parallel compositions [10] , [11] . Hypersignal Processing (HP) theory provides a unified mathematical model for advancing 1D signal (voice and time series) processing to 2D (images) and nD (generic hypersignals) processing [14] - [18] . The hypersignals may be embodied by sequences of images (videos), language expressions and semantics, knowledge structures, neural networks, and AI 4 systems. Therefore, HP demands novel theories, mathematical means, and algorithms [16] - [18] .For instances, the HP theory models hypersignals as follows:where B stands for a byte, T for time, S for a string, and Θ for an instance of an abstract hypersignal.More generically, the hyper Structure Model (SM) is introduced to model complex hyper signals and entities. For example, the SM model of the color scheme of an image signal is formally modeled as:where the 2D frame is represented in six forms including FC (color), FG (gray), FB (black/white), FR* (red), FG* (green), FB* (blue), and the composition FC = (FR*, FG*, FB*).A paradigm of HP towards COVID-19 is represented by Image Frame Algebra (IFA) [15] , [18] , which processes and diagnoses suspectedly infected lung images by efficient and accurate hypersignal handling according to a set of IFA operators. In IFA, a generic image model is an SM based on Eq. (7). According to IFA, the differential algorithm for COVID-19 images manipulations is implemented as follows:The operations of image differentiation in IFA may be expressed according to Eq. (8) as follows:where the first model expresses a differentiation between the left and right images of a symmetric structure such as lungs, breasts, and the brain. The second model denotes a sequential differentiation of image series with respect to time. For instances, the results of COVID-19 affected lung images, brain tumors, and breast tumors may be diagnosed according to the generic image differential algorithm (Eqs. (8) and (9)), respectively, as shown in Fig. 2 .

III. APPLICATIONS AND IMAGING MODALITIES FOR DIAGNOSIS/PROGNOSIS OF COVID-19 IMAGES

As stated previously, chest imaging provides an important source of data for diagnosis/prognosis of COVID-19 infection, assessment of treatment response, and monitoring of COVID-19 patients. In brief, several recent studies have been conducted to investigate specific characteristics of Coronavirus disease on chest images that can be used for design of processing/learning models. Different types of chest imaging patterns and distribution of lung involvement are related to the severity/stage of the COVID-19 infection and can help construct predictive SP/DL models to make decisions on hospital admission versus home isolation, non-ICU hospital admission versus ICU admission, on monitoring the treatment process and on the time of home discharge.In this section, we first present an overview of potential applications of SP/DL models for the diagnosis and predictive prognosis of COVID-19 infections. Then, we present the required medical background related to COVID-19 for development of SP/DL models and will review different imaging modalities. Advantages and limitations of each modality is discussed together with its application in different stages of COVID-19 management. Generally speaking, applications of SP/DL models for COVID-19 diagnosis/prognosis can be classified into the following four categories:• Diagnosis of COVID-19 Pneumonia from other Community Acquired Pneumonia (CAP): The most common 5 COVID-19 symptoms (cough, shortness of breath, and fever) overlap with CAP symptoms. CAP is mainly caused by a bacterial infection but can also be caused by viruses. In most cases, microbiological tests for CAP such as cultures of sputum and blood, are time consuming with poor sensitivity and specificity, and are not enough to identify the main pathogen [19] . Thus, the Polymerase Chain Reaction (PCR) test via nasopharyngeal or oropharyngeal swab has been used for correct identification of the source of the viral cause of CAP (like influenza) [20] . For COVID-19, a variation of PCR test, the RT-PCR, has been used as a gold standard [21] . Due to the test inaccuracy, the decision on treatment may be incorrect, i.e., antibacterial drug therapy can be administrated to all CAP patients who may not be confirmed COVID-19 positive, while for patients tested positive for COVID-19 this treatment is not required [19] . Cases of negative RT-PCR with persistent COVID-19 symptoms are submitted to chest imaging evaluation. This application domain will be further discussed in Sub-section IV-D, where different SP/DL models developed for COVID-19 diagnosis are presented.• Localizing COVID-19 Lesions and Identifying their Types:The pattern and extent of chest imaging findings is related to the stage and severity of COVID-19 and affects the treatment decision making. In Sub-section IV-A, we will further describe applications of SP/DL models in localizing involved areas and demonstrating imaging features on CT scans.• Outcome Prediction (COVID-19 Prognosis): To efficiently manage the limited medical resources during the pandemic, it is vital to accurately predict the risk of poor outcomes in COVID-19 patients. Some essential outcomes in COVID-19 patients are as follows:• Mortality risk; • Progression to severe/critical stage; • Need for ICU admission/mechanical ventilation, and; • Length of hospital stay. Predictive models are required to compute the probability of poor outcomes to help health-care professionals deliver appropriate services to high-risk patients. This application domain will be presented in detail in Sub-section IV-B.• Severity Assessment of COVID-19: Chest imaging can be used to assess the lung infection severity in COVID-19 patients [19] . Calculation of percentage of parenchymal involvement and CT severity score can be achieved by segmenting the infected regions and lung areas in chest images. This is required to evaluate and quantify severity, then prediction of prognosis of the COVID-19 infection. In Sub-section IV-C, we will present different SP/DL models developed for computing lung infection rate and CT severity score metrics as two commonly used criteria for severity assessment of COVID-19 infection.

A. Imaging Modalities and Radiological Characteristics of COVID-19

The Fleischner Society and the American College of Radiology, among others, recommend CT scan and CXR for COVID-19 patients with moderate to severe cases [23] . Among the chest imaging modalities, the CXR is less sensitive, and less specific compared to CT. The advantages of CXR over CT include its fast availability, ease of execution, and minimization of in-hospital transmissions. In addition, the CXR findings correlate well with CT findings [22] . In some situations where a fast assessment is necessary, the Point-of-Care lung Ultrasound (POCUS) offers a radiation-free imaging modality with higher accuracy in patients without any previous cardiopulmonary disease [24] . In what follows, application of the above-mentioned imaging modalities for COVID-19 diagnosis/prognosis will be discussed in detail.1) Computerized Tomography (CT) Scan: There has been considerable attention on CT imaging as the most useful imaging modality for representing COVID-19 infections. A study [25] on 51 patients with positive nucleic acid testing reported that only 3.9% of patients were misdiagnosed based on their chest CT images. Fig. 3 shows common CT patterns in COVID-19 patients, where the most prevalent are "Ground Glass Opacities (GGOs)" and "Consolidations". GGO is a hazy transparent opacity that does not conceal lung vessels and bronchial areas [26] . In a consolidation pattern, the air in the alveoli and peripheral bronchioles is replaced by fluid such as pus, water, blood, or an inflammatory material, obscuring the underlying distal airways and vascular margins [26] . In a research study on 645 confirmed COVID-19 patients, 88% of patients showed either pure GGOs or consolidation or both [27] . The appearance of pure GGO is more common in the early stage of the disease, while the appearance of GGOs with consolidations is more frequently seen in the progressive stage [28] . Another common CT pattern associated with COVID-19 is the so-called "Crazy Paving" referring to thickened interlobular septa and intralobular interstitium superimposed on GGOs [26] . The crazy paving pattern is more commonly seen in the progressive stage of the disease [28] . The appearance of the crazy paving/consolidation patterns as a sign of disease progression/severity can help radiologists evaluate the disease stage. Interlobular septal thickening, air bronchogram, and vascular enlargement are other CT findings in COVID-19 patients [28] .Distribution of Lung Involvement in COVID-19: CT findings of COVID-19 infections demonstrate that most of the COVID-19 patients have had "Bilateral" and "multifocal" lung involvements. Bilateral involvement means that the lesions are distributed in both the right and left lungs, and multifocal involvement implies that more than one lobe (from five lobes) of the lung is affected by the disease. A systematic review of COVID-19 imaging findings [28] declared that in 17 out of 36 studies (78.2%), the number of patients with bilateral lung involvement had been higher than the patients with unilateral involvement.Researches also showed that COVID-19 lesions in most of the cases are distributed in lower lobes and have a "Peripheral" instead of central distribution [28] , [30] . Similarities between CT features of COVID-19 with other viral pneumonia pose limitations in using CT images to diagnose COVID-19. However, in a study of 58 patients [31] , six of seven radiologists could distinguish COVID-19 from other types of [29] . (b) Axial CT image of a 60-year-old woman, scattered consolidation patterns with mainly peripheral distribution [29] . (c) Axial CT image of a 51-year-old man, the appearance of GGOs (white arrow) and consolidations (red arrows) [29] . (d) Crazy-paving pattern in axial CT image of a 43-year-old woman [30] . All CT images have been obtained without contrast enhancement. Table I . [34] used a severity measure for COVID-19 patients, referred to as the CT score, that measures the extent of involvement based on a semi-quantitative scoring for each of the five lobes. The score ranges from 0 to 5, which is computed as shown in Table II . The overall CT score would be between 0 and 25, which is the sum of the lobar scores (some studies use a different scoring scale, which ends up to a CT score between 0 and 20 [30] ). Francone, et al. [34] conducted research on 130 COVID-19 patients and evaluated the correlation between CT score and disease severity. They showed that the CT score is strongly correlated with the COVID-19 clinical stage and severity. For patients in severe or critical categories, CT score is significantly higher than patients in the mild category [34] . CT score greater than 18 (out of 25) can be used as a predictor of mortality in COVID-19 patients [34] . CT score is highly correlated with patients' age. In [34] , authors revealed that CT score in patients with age range > 50 was significantly higher than those in the age range of 26-50.For patients in late-stages of the disease, the CT score is higher than those in early-stages. CT score, together with patients' age, can be used to predict COVID-19 patients' death. 2) Chest Radiography (CXR): Some studies report that CXR images often show no lung infection in COVID-19 patients at early stages resulting in a low sensitivity of 69% for diagnosis of COVID-19 [35] . However, CXR is helpful for prediction of clinical outcome and for detection of COVID-19 in areas with limited access to reliable RT-PCR testing kits. The most commonly observed patterns in CXR of COVID-19 patients are GGOs and consolidations with bilateral peripheral distribution [35] . Pre-existence of medical conditions such as heart or other lung diseases will make the interpretation of CXR images challenging. Therefore, the interpretation of CXRs in younger patients would be more reliable and predictive. In Reference [36] , the authors developed a scoring approach for severity assessment and outcome prediction of COVID-19 patients between the ages of 21 to 50 years based on their CXR images. In their scoring system, each lung is divided into three zones. A binary score is then given to each zone based on the appearance/absence of COVID-19 abnormalities, and the total score would be in the range of 0-6. Their study on 338 patients demonstrates that there is a significant correlation between CXR score greater than two and hospital admission. They also reported that a CXR score greater than three could predict the need for intubation. Using lung Edema severity measure, referred to as RALE score, the authors in [37] quantify the extent of lung involvement and compute correlations with the risk of ICU admission for COVID-19 patients. Recent research works have demonstrated potentials of developing SP/DL-based models for grading the disease stage and performing outcome-prediction using CXR images.3) Ultrasound: Beside the advantages of using CT or CXR combined with RT-PCR test for a correct and precise diagnosis of COVID-19, these imaging modalities have limitations, including diagnostic accuracy, logistic challenges, timeconsuming assessment and the use of ionizing radiation [24] . Despite low sensitivity of Ultrasound for diagnosis of COVID-19 patients in mild and moderate categories, lung ultrasound has shown high-sensitivity results in critical cases [38] . Due to its low cost, portability, ease of use, and being radiation-free, lung ultrasound can play a crucial role in the follow up and monitoring patients in the ICU. Furthermore, Ultrasound has been widely used for the diagnosis and monitoring of COVID-19 in pregnant women. In Italy, health professionals used lung ultrasound as a screening tool and developed a lung ultrasound score for evaluating the severity of the disease in COVID-19 patients [39] .In another study with 93 patients, where 27 (29%) of them were tested positive for COVID-19 by RT-PCR or CT, the Ultrasound imaging achieved a sensitivity of 89% and specificity of 59% [24] . Considering a subgroup of 37 patients without any cardiopulmonary disease, the assessment based on Ultrasound revealed and sensitivity of 100% and specificity of 76% [24] . Thus, Ultrasound represents a valuable imaging modality for the detection or assessing COVID-19 severity mainly in patients without any medical history of cardiopulmonary disease.

COVID-19 CT Scans & CXR Datasets:

To assure model generalization for clinical use, it is beneficial to train SP/DL models based on a diverse set of dataset acquired from different scanners, different health centers covering a wide range of patients. Table III provides an overview of the available CT imaging datasets along with their COVID-19 related information. CT images represent different resolutions and contrasts depending on the type of scanner, image acquisition approach, and the thickness of the slices. It is, therefore, necessary to make CT images consistent before feeding them into the processing and learning models. For a list of available CT imaging datasets along with their COVID-19 related information please refer to Reference [29] . Given the heterogeneity of the data source, available data collections comprehend a wide sort of equipment, images characteristics and diagnosed disease. Table IV presents datasets of the two biggest data collection initiatives. Several other datasets are under development once when new data become available it is promptly aggregated by those initiatives. Given the heterogeneity of the data source, these data collection comprehends a wide sort of equipment, images characteristics and diagnosed disease.

IV. DEEP LEARNING RADIOMICS SPECIFIC TO COVID-19

In this section, we present different DL-based Radiomic models specific to the analysis of COVID-19 infection. In particular, we focus on the following four different application domains of discovery Radiomics: Segmentation of COVID-19 lesions (presented in Sub-section IV-A); Predictive models for outcome prediction in COVID-19 patients (described in Sub-section IV-B); DL/SP models for severity assessment (presented in Sub-section IV-C), and; Diagnosis and classification of COVID-19 cases, which are detailed in Sub-section IV-D.

A. Segmentation of COVID-19 Lesions

In this sub-section, we provide an overview of segmentation networks developed in the context of COVID-19 from different aspects as presented in Fig. 4 . Segmentation networks are image-to-image DL models that are trained to produce a mask indicating the region of interest. Segmentation allows physicians to identify the type and location of lesions; Evaluate the extent of lung involvement, and; Quantify the lung severity measures. Depending on the objective, they one segment the COVID-19 lesions, lungs, and lobe regions. Segmentationbased infection quantification models can be used to evaluate effectiveness of different treatment solutions.

Imaging Modality used for Segmentation of COVID-19

Lesions: Since CT images provide the most accurate COVID-19 manifestations for grading and evaluation of infections, they have been widely used in the context of COVID-19 segmentation. The goal in this context is localization of COVID-19 infections and/or grading the disease stage. In the literature, the focus was mainly on development of 2D models for segmentation of lung infections in each CT slice [49] - [51] . There have also been some 3D segmentation models that take the 3D CT volumes as input and segment the lung abnormalities on a patient-level basis [52] , [53] . Since the use of portable CXRs is more feasible for patients in ICU, it is essential to develop segmentation models for severity assessment of COVID-19 patients based on CXR images. A study on 2, 951 COVID-19 CXRs, performed the lung infections segmentation as the first step of their COVID-19 diagnosis pipeline [54] . Using a human-machine collaboration, they provided the first COVID-19 CXR dataset with the ground-truth infection masks. Segmenting the lung infections using a U-Net model with DenseNet-121 yielded a higher performance in their classification framework [54] .Region of Interest (RoI): The region of interest would be different in COVID-19 segmentation models based on the Researchers who aim to quantify the extent of lung involvement and determine the COVID-19 severity measures consider segmenting lung/lobe regions besides the COVID-19 lesions. Advanced segmentation models can be trained to quantify different severity measures such as PO, PHO, CT score, and LHOS, based on CT images. This will be further discussed in Sub-section IV-C.Next, we investigate different DL architectures proposed for the segmentation of COVID-19 abnormalities. 1) DL Architectures for Segmentation of COVID-19 Lesions: Segmentation is considered an essential step in the severity/stage assessment of COVID-19 patients. However, comparing to classification models, limited number of research works have focused on segmentation models for COVID-19. Generally speaking, segmentation models (mostly developed based on CNNs) contain a contracting path (encoder) for extracting informative features from input images and an expanding path (decoder) for reconstructing the mask representing the regions of interest. Unlike classification models, typically, there are no fully connected layers in segmentation models. U-Net network [57] and its various extensions are the most commonly used architecture for segmentation of COVID-19 lesions. There are few works developed based on other successful segmentation networks. Some researchers have proposed innovative encoder-decoder networks for segmentation of COVID-19 lesions. Below, we present COVID-19 segmentation architectures classified into the aforementioned three main categories:(ii) U-Net-based Segmentation Models: The majority of researches for segmentation of COVID-19 abnormalities have been developed upon the U-Net model. In U-Net [57] , skip connections transfer the extracted features from the contracting path to the corresponding layer in the expanding path. This helps the model to better understand visual details of images making it an ideal architecture for segmentation in the medical domain. Adoption of pre-existing CNNs like DensNet and ResNet blocks in the encoder path of the U-Net will result in extracting higher resolution features from CT images [33] , [58] . Multi-scale feature fusion, i.e., integration of dilated convolutions with different dilation rates, can be added into U-Net-based segmentation models to help capture COVID-19 abnormalities in different scales [59] . The current focus is on increasing performance in segmenting the COVID-19 lesions. In this regard, References [49] , [55] , [66] considered incorporation of spatial and channel attention mechanisms within the U-Net architecture.The authors in Reference [49] proposed a new attention mechanism that enables the basic U-Net model to better understand the contextual information from CT slices and perform the segmentation of COVID-19 abnormalities more accurately. Commercial U-Net-based soft-wares have also been used in some researches for quantification of COVID-19 abnormalities and determining the severity of the disease [32] , [ 2) Hand-Crafted Radiomics: Hand-crafted radiomics refers to the process of extracting several quantitative and semiquantitative features from the ROI with the ultimate goal of diagnosis/prediction. Compared to DL techniques, Handcrafted radiomics is less common in the problem of COVID-19 analysis, as it requires fine delineation of the infected regions and a prior knowledge of the types of the features to extract. Nevertheless, it benefits from more interpretability, as the features are engineered. As shown in Fig. 5 , Handcrafted radiomics, utilized in a few COVID-19 studies, follows a multi-step process, in the first of which infected regions are annotated. Consequently, several features are extracted from the segmented regions and fed to a conventional model, such as Support Vector Machine (SVM), logistic regression, and decision tree, for making the final decision. Hand-crafted features cover a wide range of categories, including firstorder (basic intensity and shape-based features), second-order (texture features extracted from various matrices), and more advanced features such as those calculated from Fourier and Wavelet transforms. Intensity features [71] , shape-based [72] , and/or texture-based features, as well as other COVID-19 related features such as CT quantification metrics can be leveraged [58] , [69] . Radiomics in COVID-19 studies are mostly used in adverse outcome prediction models, explained in the next section. It is also possible to develop hybrid frameworks, where both hand-crafted and DL-based features are combined. Such methodology is adopted in Reference [70] by combining GAN generated features with pre-defined handcrafted ones. 

B. Predictive Models for Adverse Outcome Prediction in COVID-19 Patients

As stated previously, for efficient utilization of limited medical resources during the COVID-19 pandemic, it is critically important to accurately predict mortality risk, progression to severe/critical stage, need for ICU admission/ventilation, and the length of hospital stay. In this regard, development of predictive models is essential to compute the probability of poor outcomes and help health-care professionals deliver appropriate services to high-risk patients.Although image-driven features have shown high correlation with COVID-19 outcomes, they are not the only influential factors. In other words, radiologists use image-driven features together with other clinical and risk factors to make the final decision. Some of the clinical/laboratory information used for COVID-19 outcome prediction are patients' symptoms, laboratory test results, oxygen saturation, and comorbid diseases. Chronic lung disease, obesity, hypertension, cardiovascular diseases, and diabetes are examples of comorbidities that will increase the risk of adverse outcomes in COVID-19 pneumonia. In this section, we focus on predictive models that image-driven features to estimate the risk of adverse outcomes in COVID-19 patients. As shown in Fig. 6 , in what follows, predictive models are categorized and described in terms of their: (i) Model structure, and; (ii) Target outcome.1) Model Structure of COVID-19 Outcome Prediction Models: Most COVID-19 outcome prediction studies exploit both chest CT images and clinical/laboratory data in their models. To effectively benefit from heterogenous data resources, conventional ML methods or hybrid models can be utilized, as explained below.(i) Conventional ML Models: In some COVID-19 predictive studies, CT Radiomics and quantification features are extracted in a pre-processing step. Extracted features are then used with clinical/laboratory data to train a shallow classifier such as logistic regression or random forest. For instant, Chao et al. [79] used CT features including lobe-wise quantification features and whole lung Radiomics together with patients' clinical information including age, sex, vital signs, and laboratory findings to predict the need for ICU admission in COVID-19 patients. They used a DL-based segmentation model to measure CT quantification features. Integrated input data from various types and resources are then fed into a random forest classifier for outcome prediction. Following this study, one can conclude that adding clinical information to CT features can improve the overall outcome prediction performance.(ii) Hybrid Models: Hybrid models (such as multiple-models, mixture of experts, and ensemble models) are of high importance in the field of medical imaging, typically, improving the initial results. While hybrid models can be developed in a variety of forms, they are mostly adopted in COVID-19 analysis in two main ways, i.e., combinations of Hand-Crafted and Clinical/Laboratory features or combination of DL-driven and clinical/Laboratory features, as described below: [78] , [115] . In this study, gender, age, severity grade, and chronic disease history are combined with the chest CT scans through a joint CNN-MLP network to distinguish between high and low-risk COVID-19 patients. In another study [78] , blood and urine test results of 1, 170 patients are used as the clinical information.The developed model consists of two successive CNN networks for analysis of CT images, i.e., a DNN network for analysis of clinical features, and a penalized logistic regression to integrate image-driven DL features and the DL features extracted from clinical data. Improvements are reported when image-driven and clinical features are jointly used.2) Target Outcomes in COVID-19 Patients: Generally speaking, in the context of COVID-19 prognosis, the target outcomes of interest include progression to severe/critical stage, mortality risk, need for ICU admission/ventilation, and the length of hospital stay. Below, we present different COVID-19 outcome prediction models based on these target outcomes:• Risk of Progression to Severer Stages: Li et al. [58] aimed at measuring the progression of the disease by monitoring the Portion of Infection (POI) and the av- 

C. DL/SP Models for COVID-19 Severity Assessment

Severity essentially refers to how much the lungs are affected and involved in the disease. COVID-19 severity assessment is of high importance due to its unique role in risk management and resource allocation. In this sub-section, as shown in Fig. 7 , we present existing severity assessment methodologies. 1) Severity Assessment Types: Generally speaking, two types of severity assessment can be defined within the COVID-19 literature. The first one is to consider a classification approach, where different discrete labels are defined to assess the severity. The second type, however, aims at calculating the degree/portion of lung involvement as a measure of severity. Although, the second type, referred to as "quantification", is often followed by a classification paradigm, degree of lung involvement is essentially embedded in the feature vector. Below, we further elaborate on these two severity assessment types:(i) COVID-19 Severity Classification: Similar to most of the classification problems, COVID-19 severity classification can be solved using either hand-crafted or DL methods.• Hand-crafted Radiomics: While different engineered features have the potential to distinguish between severe and non-severe cases, Ghosh et al. [88] proposed a handcrafted feature, referred to as the L norm . This feature is defined using the maximum bone reference (B), minimum air reference (A), and the mean gray scale intensity of the lesion (L), as followsThe optimum cut-off value to distinguish between severe and non-severe cases using the L norm is then obtained based on a Receiver Operating Characteristic (ROC) curve analysis. Other traditional hand-crafted features, such as first-order histogram features and/or texture-based ones can be incorporated followed by a regression model to distinguish between severe and non-severe patients. First-order histogram features are also used in Reference [85] for severity classification. • Deep Learning: To identify discrete severity scores of the COVID-19 patients, CNN-based models can alternatively developed [82] . A two stage DL framework is proposed in Reference [84] for COVID-19 severity classification. In the first stage, CT scans are individually fed to a U-Net model, whose extracted features are stored for the second stage. Through the second stage, the feature vectors are fed to a bi-directional LSTM model, for the final classification.(ii) Severity Assessment via Quantification: Although quantification is performed by calculating the lung and infection volume in most of the studies, it is also possible to adopt a different approach such as using a Siamese neural network. Below, we discuss recent works performed along these two directions:• Quantification via Volume Calculation: To quantify the COVID-19 severity, Reference [60] calculated PO and PHO. POI and the average infection HU are calculated in Reference [58] , to quantify the severity, followed by dividing the patients into two groups of severe and non-severe. Infection and GGO ratio are calculated in Reference [87] . These two measures, along with several other quantitative features, are further fed to a Random Forest (RF) classifier, to classify patients as severe and non-severe. • Quantification via Siamese Neural Networks: This approach consists of two identical models, in terms of weights and parameters, with the goal of finding the similarity between the two inputs. Beside having several applications, Siamese models, in particular convolutional Siamese neural networks, can be adopted for COVID-19 severity assessment [86] In such scenarios, the Euclidean distance between the two final layers is calculated as a measure of difference between the inputs. Therefore, the distance between a COVID-19 and normal scan can show the degree of abnormality. Utilizing a pool of normal images, the median distance can represent the severity.

D. COVID-19 Classification Models

Development of DL-based COVID-19 classification models can be approached from four main perspectives, as shown in Fig. 8 . The first aspect is the annotation dependency of the developed frameworks. The second one is whether the proposed methods consider a binary or multi-class classification, followed by the third perspective focusing on the imaging modality used for the classification, as based on the modality different solutions are admissible. The DL model architecture is another important aspect of the developed frameworks. Next, we discuss these four categories in detail. Table VIII summarizes how different studies approach the aforementioned categories.1) Annotation Dependency: Annotation dependency refers to whether the developed COVID-19 classification models rely on annotated images as inputs. Annotation can be related to either segmenting the whole lung region or the infected areas from the chest image. In this regard, we categorized studies into three groups of (i) no annotation required, (ii) lung segmentation required, and (iii) infection segmentation required. These three groups are discussed in the following: 16 [t!] COVID-19 Classification without Annotation: Studies that do not include any segmentation as a pre-processing step essentially feed the developed model with raw images. As CXR images are single slices and simpler to process compared to CT scans, they are utilized without annotation in most of the studies. Reference [102] is an example of such studies, where raw CXR images are fed to a DL model for binary and multi-class COVID-19 classification. Narayan Das et al. [119] and Islam et al. [109] also utilized CXR images without annotation for a three-way COVID-19 classification. Although using CT scans, Reference [62] is independent from segmented inputs. It exploits annotation labels in the output layer to develop a multi-task training framework. In other words, both classification and segmentation are aimed at in this work.Lung Segmentation for COVID-19 Classification: Lung segmentation is the first step in many COVID-19 classifications studies, as it eliminates unessential information. Gozes et al. [118] , for instance, used a pre-trained U-net model for this task. Since the segmentation model should be able to annotate lungs even in the presence of COVID-19 opacities, the U-net model is fine-tuned on a dataset of interstitial lung disease cases. More advanced lung segmentation models are also used in COVID-19 studies. Reference [108] , for instance, has proposed a multi-window U-Net that incorporates several windows instead of the standard Hounsfield unit (HU) window. Furthermore, this study uses a sequential information attention module to integrate all CT slices.Infection Segmentation for COVID-19 Classification: Beside lung segmentation, some COVID-19 classification studies rely on segmenting the pulmonary regions of infection. Xu et al. [112] , for instance, have used a 3D CNN model trained on pulmonary tuberculosis for infection segmentation. Although this model is not trained on a COVID-19 dataset, it can still extract candidate patches. The annotation results are consequently used to form cubic patches around the regions of infection, which are then fed to the classification model. Based on the COVID-19 characteristics, such as GGO, Wang et al. [97] have manually delineated the CT scans to extract all the ROIs, from which 2-3 patches are randomly selected as the input to the CNN model for classification purposes.2) COVID-19 Classification Types: Binary or multi-class COVID-19 classification refers to whether the problem is considered as COVID-19 versus all other possible categories as one class or all the classes are treated separately. These two approaches are investigated in the following:Binary COVID-19 Classification Problems: Reference [102] is an example of binary classification, where the goal is to distinguish between COVID-19 and non-COVID cases. Non-COVID cases include both normal and pneumonia patients. Reference [101] explores three different COVID-19-related binary classification problems, in each of which COVID-19 is classified against a different class, including viral pneumonia, bacterial pneumonia, and normal. Obtained results show that COVID-19 is best distinguishable from bacterial pneumonia. Beside positive and negative COVID-19, patients can be classified based on other clinical outcomes. Meng et al. [115] , for instance, consider high and low-risk as the binary classification labels.Multi-class COVID-19 Classification Problems: Reference [102] , beside considering a binary classification problem, tries to solve a multi-class classification consisting of three classes of COVID-19, pneumonia, and normal. The obtained accuracy, however, is lower than the binary scenario. The same categorization is followed in [109] . Reference [62] also followed a three-way classification with the difference that all diseases other than COVID-19 are considered as the "others" class to be classified against COVID-19 and normal subjects. COVID-19, pneumonia, and other diseases are considered as three separate classes in Reference [119] . Since Reference [112] have used annotated infection patches as inputs to a CNN model, it also considers a irrelevant-toinfection class to exclude incorrectly segmented areas.It is worth mentioning that unlike binary and multi-class approaches, COVID-19 classification is considered as a oneclass anomaly detection in Reference [107] , where the model's output is the anomaly score of the input, along with a confidence score that determines the model's confidence in its prediction. Consequently, subjects with a high anomaly score or low confidence score are considered as positive COVID-19.3) Imaging Modality used for COVID-19 Classification: CXR and CT are two common imaging modalities considered in the COVID-19 classification studies. These two modalities, however, require different processing strategies, as described below:(i) COVID-19 Classification via CXR Images: CXR images are 2D and as such processing techniques to incorporate the relation between images are not required. CXR images can be independent inputs to a DL model. References [102] , [109] , [119] are examples of using CXR images for classification tasks. Unlike most of the COVID-19 classification methods using CXR that incorporate the whole image at once, Oh et al. [106] extract several random patches from the input image and feed them individually to the DL model. The final decision is a majority voting over all the obtained outcomes. (ii) COVID-19 Classification via CT Scans: Unlike CXR images, CT scans are 3D in the sense that each patient is associated with several 2D slices. As a result, analyzing CT scans require specific strategies, the first of which is a slicelevel classification, where slices are treated independently with the goal of assigning labels to separate slices. Patientlevel classification, on the other hand, tries to make the final decision using all the available slices. examples of slice-level classification models, where target slices are manually selected to train the CNN model. At the test time, however, these studies, average over all the probabilities to form the patient-level classification. Therefore, the underlying studies can be considered as cross-sections of slice-level and patient-level classification, bringing us to the discussion in the next part, i.e., patient-level classification. • Patient-level Classification: Patient-level classification using CT scans requires a voting strategy to combine the slice-level outcomes. The voting mechanism is of particular importance as the whole CT volume cannot be typically processed at once. Different voting mechanisms have been developed in the literature including the following items:-Volumetric Scoring: In Reference [118] 2D slices are first processed to form the slice-level outcomes. Summing over the activation maps of the detected positive slices, consequently, results in the aforementioned volumetric score. It is worth mentioning that only activations above a pre-defined threshold are considered in the summation. The obtained COVID-19 score can also be considered as the extent of the disease in a patient's lungs. -Pooling Operations: For patient-level classification, one approach [105] is to combine different models (e.g., parallel CNNs) in a parallel architecture. Results from individual slices can then be aggregated through pooling operations. Similarly, Li et al. [93] incorporate parallel CNNs, results of which are aggregated through a max pooling operation. -Whole CT Volume: To leverage the information from all the CT scans and capture their relations, Wang et al. [111] feed their developed CNN model with the whole CT volume, which is concatenated with the segmented lung mask. The same strategy of feeding the whole CT volume is also used in Reference [115] . -Bayesian Merging: A Noisy-or Bayesian function is adopted in Reference [112] to combine outcomes of several infection patches. -RNN-based Merging: Using Recurrent Neural Networks (RNNs) is another strategy to combine the slice-level information and consider the spatial relations. This group of models are discussed in Section IV-D4. -Multi-stage Frameworks: Designing a multi-stage framework is also a common patient-level classification approach. Mei et al. [89] , for instance, have designed a two stage workflow, where in the first stage abnormal slices are detected using a previous pre-trained pulmonary tuberculosis (PTB) detection model. Top ten candidate slices are then fed to another CNN, in stage two, to identify slices with positive COVID-19. Final outcome is ultimately set as the average of slice-level prediction of a patient's ten most abnormal candidates. The same multi-stage strategy is followed in Reference [116] , with the difference that the CNNs are replaced with capsule networks, as described in Section IV-D4. 4) DL Architectures for COVID-19 Classification: Although different DL architectures are applicable to the task of image classification, in the COVID-19 scenario, discriminative models including CNNs, RNNs, and capsule networks are the most commonly used ones. These networks and how they are incorporated in COVID-19 classification studies are explained below.CNN-based COVID-19 Classification Models: CNNs are stack of convolutional and pooling layers, often followed by fully connected ones. Since the trainable filters share weight across the whole image, these networks are computationally effective, and can extract local features from the input. CNNs have shown promising results in the field of image processing including COVID-19 classification. Although it is possible to design a CNN from scratch, most of the studies have built their models upon pre-existing successful CNN models as described below:• Pre-existing CNN models: Since the start of the outbreak, the following pre-existing CNN models for COVID- [111] consists of three subsequent blocks, the first of which is a vanilla 3D CNN, followed by a residual block. The last part is a progressive classifier, containing convolutional and fully-connected layers. Beside focusing on designing layers of a CNN, another strategy is to feed the model with information other than the raw image. Such strategy is leveraged in Reference [112] , where the distance between the center of infection and pleura is concatenated with a fully-connected layer. This distance can contribute to a more accurate classification, as COVID-19 infection has a pleural distribution, partly distinguishing it from other diseases. Meng et al. [115] utilized patient's clinical factors, such as gender, age, and chronic disease history, as the additional information to be concatenated with the CNN's fully connected layer. More heterogeneous factors, including travel and exposure history and symptomatology, are incorporated in the model designed by Mei et al. [89] .RNN-based COVID-19 Classification Models: RNNs are especially useful in medical imaging when the goal is to process the whole volume or analyze follow-up studies. Since RNNs are subject to the problem of vanishing gradients, LSTM networks are commonly used as an effective alternative. The vanilla LSTM is not designed for extracting local features from images and as such this network is often combined with a CNN, to make use of its weight sharing advantages. Such a model is utilized in Reference [109] for COVID-19 classification, resulting in a CNN-LSTM design. In the underlying study, 12 convolutional layers are first incorporated to extract features from CXR images. The output of the CNN is then fed to an LSTM, the result of which determines the probability of COVID-19, pneumonia and normal classes. While a conventional LSTM considers only forward relations, bi-directional LSTMs additionally take the backward relations into account. Such models are incorporated in Reference [113] for COVID-19 classification.CapsNet-based COVID-19 Classification Models: CapsNets are relatively new deep learning architectures, proposed to solve the incapability of CNNs to recognize spatial information. Each capsule in a CapsNet, consist of several neurons to represent an object instantiation parameters, as well as its existence probability. The main feature of the CapsNet is its routing by agreement process, through which capsules in a lower layer predict the outcome of capsules in the next layer.The parent capsules take these predictions into account, based on the similarity (agreement) between the prediction and actual outcome. Using the routing by agreement, CapsNet is capable of recognizing spatial relations between image instances, and therefore handle much smaller datasets, compared to CNNs. Reference [96] has recently exploited CapsNets for the problem of COVID-19 classification using CXR, showing improve-ments over the CNN counterparts. The proposed architecture, referred to as COVID-CAPS, consists of several convolutional, pooling, and capsule layers, the output of which determines the probability of positive COVID-19.

V. CHALLENGES, OPEN PROBLEMS, AND OPPORTUNITIES

In this section, first, we focus on limitations and challenges of developing COVID-19 diagnosis/prognosis models as shown in Fig. 9 . Then, we discuss open problems and potential opportunities for SP research by highlighting problems and challenges of developing SP/DL models for COVID-19 management.

A. Challenges in Developing COVID-19 Diagnosis/Prognosis Models

The ultimate goal of developing COVID-19 diagnosis/prognosis models is to be used in clinical applications and reduce the healthcare system's workload during pandemic conditions. Some models proposed for diagnosis and prognosis of COVID-19 have shown successful results in real applications and enhanced the performance of junior radiologists to senior-level [52] . However, some common issues such as the risk of bias and over-fitting may cause poor generalization of such models. The leading causes of these issues are: (i) Lack of sufficient data; (ii) Lack of labeled/annotated data, and; (iii) Imbalanced dataset. These three categories are described below together with solutions developed in COVID-19 studies to overcome them:1) Lack of Sufficient Data:: There is no doubt that preparing a high-quality dataset is the most critical part of developing a data-driven model. Collection of sufficient data for training robust COVID-19 models is challenging because: (i) COVID-19 is a new arising disease; (ii) Restrictions imposed to preserve patients' privacy, and; (iii) Health centers' strict data sharing protocols. On the other hand, despite the robustness of CNNs in hierarchically extracting high-value features from images, they cannot recognize the spatial relationships between those features. Due to various shapes and complex appearances of COVID-19 lesions, a large number of chest medical images are required to avoid over-flitting and ensure the model generalization. Data augmentation, transfer learning, multi-task learning, and the use of Capsules networks are some solutions to tackle these problems.Data Augmentation, compensates for the lack of large training dataset, by generating several variations of the original samples [118] . Random cropping, zooming, and flipping, for instance, are applied to the samples in Reference [107] . Flipping, random rotation, and lighting are also adopted in Reference [100] to further enlarge the training set. Random Gaussian noises is another data augmentation technique that has been used in Reference [59] . Other than applying different transformations to the dataset, Generative Adversarial Networks (GANs) can be used to generate new instances [110] . GANs produce fake images and forces the algorithm to discriminate them from the original ones, which makes the model robust on unseen images. Such strategy is utilized in Reference [110] , where a convolutional GAN is leveraged for COVID-19 data augmentation. Similarly, a conditional GAN, referred to as COVIDGAN, is proposed in Reference [95] , for CXR data augmentation.Transfer Learning, refers to pre-training a model using an external dataset with the goal of encouraging the model to learn meaningful filters. The model is then fine-tuned on the main dataset, which might be a small one for an independent training. Transfer learning has shown promising results especially in field of medical imaging, where large datasets are scarce. While most of the existing studies utilize natural image datasets for pre-training, it is also possible to leverage similar medical samples as described below:• Natural Image Dataset: Reference [119] utilized transfer learning to fine-tune a pre-trained Xception model using a COVID-19 dataset. Transfer learning is also explored in Reference [101] to pre-train five well-known CNN models, namely ResNet50, ResNet101, ResNet152, Incep-tionV3 and Inception-ResNetV2. ImageNet is the common choice for pre-training the CNN models [100] , [107] , [118] . Some COVID-19 segmentation models incorporated an encoder pre-trained on ImageNet in their segmentation models to achieve more accurate results [51] . • Medical Datasets: Although pre-training with natural image datasets is very common in COVID-19 classification, it is also possible to leverage similar medical datasets, having the advantage of providing more useful filters and features. Such strategy is recently adopted by Afshar et al. [96] , where the proposed CapsNet is pre-trained on a CXR dataset collected for a completely different task. In the fine-tuning phase, all the convolutional layers are kept fixed and only the capsule layers are re-trained on the COVID-19 dataset. Reference [63] trained their COVID-19 segmentation network on a dataset containing 80% of lung cancer CT images and 20% of COVID-19 CT samples. However, the model failed to segment the COVID-19 regions of infection in test set due to the significant appearance differences between lung cancer tumors and COVID-19 lesions.Multi-task Learning is a popular strategy to leverage the information available in several related tasks and make use of small datasets associated with different end goals. Multitask learning is shown to be effective in reducing overfitting and can be further divided into two categories, i.e., (i) Hard parameter sharing, and; (ii) Soft parameter sharing. In the former category, different tasks explicitly share several layers. In the latter, however, separate models are trained for separate tasks and the parameters are encouraged to take close values. With this in mind, Amyar et al. [62] proposed a DL model to perform COVID-19 classification, segmentation and reconstruction at the same time, using the hard parameter sharing strategy. The model begins with an encoder to encode all CT scan into a latent space for subsequent analysis. For the segmentation and reconstruction tasks, the latent space is decoded into the original feature space. In the classification scenario, however, the latent space goes through a MLP for the final three-way classification. It is also worth mentioning that the encoder-decoder architecture follows the well-known U-Net design. While Mean Squared Error (MSE) is utilized for the reconstruction part, dice score and cross-entropy losses are adopted for segmentation and classification, respectively. The final loss is the sum over all the three losses.Capsule Networks, which are less data-demanding in comparison to CNNs and can be trained using smaller datasets. Incorporation of Capsule Networks for COVID-19 diagnosis models and their superiority when having a limited dataset at hand has been discussed in [96] . Capsule networks can be adopted instead of CNNs in medical segmentation networks. Capsule network-based segmentation network can potentially outperform its CNN-based counterparts. Due to data limitations for COVID-19 lesion segmentation, there is a potential for further investigation of replacing CNNs with Capsule Networks in segmentation models.2) Class-Imbalanced Dataset: This problem occurs in situations where samples associated with one class outnumber those of the other class, which is a common problem in most real-world problems, including COVID-19 diagnosis/prognosis. In training a model for diagnosis of COVID-19 from normal/CAP cases, we usually have a fewer number of COVID-19 instances and a larger number of other classes. It is the same situation in segmentation models, where the pixels labeled as COVID-19 lesions are in the minority compared to the background pixels. In such scenarios, the model can be biased toward the majority class. To tackle this issue, one can consider: (i) Modified loss functions, or; (ii) Re-sampling techniques as possible solutions, as discussed below:Modified Loss Functions, which improve the model performance by assigning more penalty to the mis-classified instances/pixels of the minority class. Weighted binary crossentropy is a commonly used loss function in class-imbalanced classification/segmentation models [49] . Focal Tversky loss is a re-weighted loss functions that optimizes the coverage of predicted and ground-truth masks by assigning more weights to the target pixels. Some COVID-19 segmentation studies adopt a combination of modified loss functions to improve the model performance in both image-level and small ROIs [50] . Reference [108] , [115] developed a COVID-19 diagnosis model under supervision of a focal loss which assigns smaller weight to easy examples, and thus they contribute less to the loss function.Re-sampling Strategies, that handle the class imbalance problem by either over-sampling the minority class instances or under-sampling from the majority class. Xi et al. [123] adopted an over-sampling strategy in their COVID-19 diagnosis model to adjust the samples of different classes in each mini-batch. Li et al. [121] introduced a new off-line sampling strategies that ranks the non-COVID-19 samples based on their diversity and difficulty. The most informative samples are then fed into the classification model. Their approach could significantly decrease the training time while achieving comparable results.3) Lack of Labeled/Annotated Data: One of the most challenging problems when developing medical segmentation networks is the lack of pixel-level labeled images. Pixellevel labeling of medical images by experienced radiologists is time-consuming. When it comes to COVID-19 infections segmentation, since the regions of infection are blurry with hardly-distinguishable boundaries from healthy lung tissues, the experts' annotation may not be consistent, making it necessary to work with a team of radiologists. Manual annotation of one COVID-19 CT volume takes 1 to 5 hours [56] . Some helpful solutions to overcome this problem are as follows:Human-in-loop Annotation Process, which is a humanmachine collaboration approach to ease and accelerate the annotation process. Shan et al.. [56] proposed an efficient human-in-the-loop system by the collaboration of radiologists and the DL-segmentation model, which could dramatically reduce the annotation time.Semi-supervised Learning, where a few annotated samples together with a large number of non-annotated CT images are fed to the network to increase the model accuracy. Combining 3D segmentation with GANs in a semi-supervised fashion can also be used to segment COVID-19 lesions. GASNet proposed in [65] is a 3D segmentation framework containing a segmentation network with embedded GANs and a discriminator that uses a semi-supervised approach to segment the COVID-19 lesions. The experimental results on three external public datasets showed that their model's performance trained on a few labeled CT volumes was comparable with fully-supervised segmentation networks trained on a large labeled dataset.Un-supervised Learning, where the model distinguishes out of distribution data in a dataset without any pre-existing label. Li et al. [121] used a new paradigm of un-supervised learning, refereed to as self-learning, to exploit helpful information from unlabeled data in their COVID-19 classification model.

B. Open Problems

In this section, we focus on open problems and potential opportunities for SP research by highlighting problems and challenges of developing SP/DL models for COVID-19 management.• COVID-19 patients suffer from dyspnea as such there are inevitable motion artifacts in the acquired images. This is in contrast to most of other medical images, where motion artifact is rarely present. The artifacts in the COVID-19 images sometimes overlap with the main areas of infection, making the diagnosis/prognosis challenging even for experienced radiologists. To eliminate the effect of artifacts, most of the studies simply remove the noisy data from the dataset. This, however, reduces the generalizability and applicability of the model in clinical practice. An alternative solution is to approach advanced artifact reduction techniques, among which adaptive techniques are of higher capability as they can adjust and track the signal under noisy conditions.• COVID-19 involves a large volume of the lung and is sparsely distributed around the lung volume. This is, in par- ticular, in contrast to medical images in which the region of interest is located in a specific location of the organ. Analyzing and extracting patterns from the COVID-19 images require sparse filtering techniques within the signal processing domain.• As COVID-19 infection is distributed in the whole lung volume, the relation between the image slices is of high diagnostic and prognostic importance, calling for specific 3D filtering and pattern recognition approaches.• A key issue with chest CT scan is exposing patients to harmful radiation. In this regard, using low-dose or ultra low-dose scanning is of high interest. In a recent study by Tabatabaei et al. [124] , it is shown that obtained low-dose CT scans have high agreement with standard-dose ones, in terms of typical findings of COVID-19. More importantly, low-dose examinations are associated with less cancer risk, especially in young women. Fig. 10 shows the obtained CT scans for three different patients at three different dose levels, i.e., standard, low, and ultra low. According to this figure, although low and ultra low-dose images have more visible artifacts, they can still reveal the presence of COVID-19 infection. The artifacts, however, can hamper the effective training of the model. Furthermore, collecting a dataset of low-dose scans may not resolve this issue, as besides dose, other factors such as the patient's weight can influence the quality of the image, leading to a wide variety of possible artifacts. This calls for SP/DL models that can cope with images at different resolutions while providing the same level of diagnosis/prognosis performance.• COVID-19 is relatively new, and as such, large datasets are not easily accessible. Therefore, the developed SP/DL models should be capable of handling small datasets and yet capturing informative features.• To encourage physicians and health professionals to confidently utilize DL models, it is important to provide explanation and interpretations on the internal behaviour of the DL models and the achieved results and therefore eliminate the "blackbox perception". Regarding the black-box nature of the deep learning models, communicating explainable outcomes to the physicians is essential for clinical adoption of implemented DL models. Several explainability techniques are leveraged in COVID-19 studies, the simplest of which is to verify the outcomes with a radiologist. This approach is, however, timeconsuming and burdensome. Techniques, providing heat-maps of the most important regions of the input image, are also popular within the COVID-19 studies. One of the commonly used heat-map techniques is Class Activation Mapping (CAM), utilized in Reference [108] at different feature levels. Gradientweighted Class Activation Mapping (Grad-CAM), visually depicting the deep model's decision, is also a CAM approach with the advantage of not requiring re-training. Grad-CAM outcome shows how the developed model pays more attention to the regions of infection of the chest radiographs in [102] , [109] . Saliency map has also shown interpretable outcomes within the COVID-19 studies [108] .Despite the advances in improving the explainability of the models, there are still examples for which the model fails to provide a clear explanation. Furthermore, heat-maps do not provide enough explanation of the unique features they used to distinguish between COVID-19 and CAP cases.• Due to the policy of protecting people's privacy and also immediate quarantine of mild cases without further examinations, scans with non-severe symptoms are missing from most of the public datasets, and models are mostly developed based on patients with severe lung lesions who are at late/advanced stages of the disease. The models, therefore, are biased towards severe cases and cannot be easily generalized.• Evaluating the developed SP/DL models' performance in an unseen domain, results in a decrease in the sensitivity of COVID-19 diagnosis. Most of the developed models, however, incorporate data coming from a single hospital, without a cross-center validation. In other words, the impact of equipment differences are not fully considered yet, and data from different sources are required to verify the generalizability of the models.• One limitation associated with many COVID-19 studies is that they try to distinguish COVID-19 cases from normal ones 23 or categorize normal and non-COVID pneumonia cases as one class. Studies who consider a separate CAP class also report a relatively poor performance in distinguishing the COVID-19 and CAP classes. This calls for developing models with stronger backbone architectures and higher capacities. Furthermore, pneumonia incidence samples are older compared to the COVID-19 ones and images from pneumonia patients with COVID-19 symptoms are not included in the datasets.• Although hybrid models, combining images and other relevant clinical information, can play an important role in COVID-19 analysis, few datasets are accompanied with demographic and clinical risk factors.• One important challenge associated with COVID-19 analysis is the disease manifestation in patients with complications other than COVID-19. Several diseases can impact the lung tissue and interfere or change the appearance of COVID-19. Interstitial lung diseases, pleural or cardiac diseases may have imaging manifestations that may mask superadded COVID-19, and make it challenging for the interpreting radiologist. As shown in Fig. 11 , it is not clear if the abnormalities are related to COVID-19. This calls for developing more advanced SP solutions and unique features to facilitate COVID-19 identification.

VI. CONCLUSION

Medical imaging plays an important role in the diagnosis and management of COVID-19 infection. Signal Processing (SP) methods coupled with Deep Learning (DL) models can help to develop robust autonomous solutions for diagnosis/prognosis of COVID-19 based on chest images. In this article, an integrated sketch is presented for designing and developing intelligent models for the COVID-19 infection diagnosis/prognosis. Advanced SP methodologies and DL models for diagnosis and prognosis of COVID-19 are presented, taking into consideration major challenges and opportunities. This article provides the SP community with a comprehensive introduction to various solutions to COVID-19 Radiomics. In addition, the article provides the required radiological background, available resources, and challenges/opportunities for extensive future SP research in this multidisciplinary domain to serve our diligent role in combating COVID-19 pandemic and possible future similar ones.

