Introduction

The current pandemic revitalized research on group testing, a methodology to reduce the number of required tests to screen a large population for a certain disease. The increased testing efficiency results from jointly testing groups, instead of subjecting each individual to a test.Specifically, we consider the scenario of probabilistic group testing as first described by Dorfman [1] , where every individual has a certain (known) probability to be infected. Probabilistic group testing is in contrast to combinatorial group testing [2, 3] where one assumes a fixed known number of infected individuals. Furthermore, we assume that while the number of tests is limited, all tests are perfectly accurate. Although the case of imprecise tests also leads to interesting resource allocation problems [4] , we will not consider it in this work. Thus, if none of the individuals in a tested group are infected, the test will yield a negative result with certainty and one test was sufficient to obtain a definite result for several individuals. If, however, the test is positive, one cannot say which individuals in the group are infected and further tests have to be conducted.Formally, a testing strategy is a deterministic algorithm, describing which groups of individuals are pooled and jointly subjected to the test. We assume that the choice of the next group can depend on the results of previously conducted tests. This adaptive group testing, is in contrast to non-adaptive group testing (for a recent survey see Aldridge et al. [5] ), where the testing strategy is fixed and all tests can thus be performed in parallel.

Previous work

The theoretical work on adaptive, probabilistic group testing started with Dorfman [1] who considered the simple strategy of testing groups of M individuals and subsequently, if the pooled test is positive, testing each individual in the group separately. Although this strategy is far from optimal, it is easy to implement and can significantly increase the testing capabilities, compared to testing every sample individually. Further research in this direction was focused on finding new, more efficient and practical testing strategies, e.g., nested testing [6] , binary splitting [7] , and array testing [8] . The binary splitting algorithms by Hwang [7] perform close to the theoretic optimum, within a factor of 1.11 of an information-theoretic lower bound, as shown by Aldridge [9] . However, such a binary splitting technique requires extensive bookkeeping and many tests need to be performed sequentially, and cannot be conducted in parallel. Simpler, two-stage procedures are investigated by Berger and Levenshtein [10] . The close relation of adaptive, probabilistic group testing to variable length source coding is well-detailed by Wolf [11] .Due to the current pandemic, several works rediscover slight variations of these results and argue for the use of group testing [12, 13] . Also, the practical implementation of group testing has seen a new surge of research, in particular, questioning the practical use in testing for SARS-CoV-2. Here, however, the focus was on the classical Dorfman testing strategy [14, 15, 16] and only few works considered more elaborate non-adaptive testing strategies [17] .Hardly any works go beyond the assumptions of perfect sensitivity and independence of the infection status of tested individuals. However, Pilcher et al. [18] takes the dilution effect into account, i.e., reduced sensitivity of tests for large groups, and Deckert et al. [19] performed a simulation study that found benefits of group testing if there is positive correlation of infection status between individuals in the same group.The common ground of all works above is that they focus on identifying exactly, which individuals are infected. This is a valid strategy and clearly the best outcome. However, there can be situations where not sufficiently many tests are available to subject all potentially infected individuals to a test. This is particularly the case when many individuals are (potentially) infected and testing resources are scarce. Here, a strategy needs to be found that uses these limited resources effectively. When insufficient tests for the entire population are available, it is unavoidable that some healthy individuals will be treated as infected and/or some infected individuals treated as healthy. For the design of a testing strategy, it is important to note, that these two events are not equally harmful in general. It might be considerably worse to have an undetected infection (false negative) present, than to treat one healthy individual as infected (false positive). A suitable balance has to be found and sensitive questions like "How many false positives are we willing to accept to prevent one false negative?" need to be answered to do so. Here, assuming that quantitative answers to these questions can be given, we propose a framework for designing and evaluating group testing strategies. Mathematically, the resulting problem is one of rate-distortion theory, a branch of information theory, established in the 1950s in a seminal paper by Shannon [20] . This connection allows us to formulate bounds on the performance of any group testing strategy. Although the problem of (combinatorial) group testing was extensively explored by information-theorists (e.g., in Ch. 24-29 in Aydinian et al. [21] and by Aldridge et al. [5] ), this rate-distortion viewpoint has apparently not been considered so far. Thus, fundamental bounds are missing even for elementary scenarios.Only recently, researchers suggested that "the scarcity of tests obviously means that it is better to use a test to detect the virus in another untested group than to try to discover who is infected in a positive group" [12] which is a first step into the direction of the rigorous theory developed here. Finally, the scenario discussed in [22] is closest to our ideas but considers only a single fixed testing strategy. We will use it in our theory for comparison and as a starting point for some more evolved testing strategies.

Contributions

We present a rigorous mathematical framework for evaluating the cost incurred by false positive and false negative assignments under a given group testing strategy. An ultimate lower bound on the expected cost that cannot be surpassed by any testing strategy is derived and compared to existing and novel testing strategies. We consider two basic scenarios in more detail: First, a toy example where all individuals are equally likely to be infected and where wrong assignments incur the same cost for each individual; and, subsequently, a division of the population into subpopulations that have different probabilities of being infected (e.g., individuals showing symptoms are more likely to be infected than individuals without symptoms) and/or different costs associated to false assignments (e.g., misclassified health care workers result in a higher cost).Our work is focused on a simple model that requires as few parameters as possible. Thus, it does not capture several aspects that might be relevant in practical scenarios, such as dependence of the infection status between individuals, compliance of individuals with their assigned health status, or imperfect test results, nor does it incorporate testing strategies into a larger disease model. Nevertheless, basic questions that were so far answered by "common sense," can be discussed on a sound mathematical basis. For example, optimal testing priorities can be shown to depend heavily on the specific scenario and subjecting only symptomatic individuals to a test is often a suboptimal decision.The rest of this article is organized as follows. In Section 2, we formulate the problem, give a mathematical definition of testing strategies, and introduce the expected cost associated with a testing strategy, as well as the minimal expected cost. Our main theoretical results are presented in Section 3. We establish fundamental lower bounds on the minimal expected cost and calculate the expected cost of various simple testing strategies. A first simple example is given to illustrate the bound and the strategies. Section 4 showcases a more complicated example. It illustrates how to allocate limited testing resources to obtain significant improvements using simple testing strategies. In Section 6, we discuss our results and their limitations. Finally, in Section 5, we provide the information-theoretic statements that underlie our main results. Detailed proofs are relegated to a technical appendix.

Problem formulation

We assume that we have a sequence of individuals and the infection status of the n-th individual is given by a binary random variable X n on Ω := {0, 1}, where X n = 1 corresponds to being infected and X n = 0 to being healthy. All X n are assumed to be independent but not necessarily identically distributed. Thus, each X n is a Bernoulli(p n ) random variable with possibly different probability Pr[X n = 1] = p n ∈ (0, 1). The second ingredient we need is a cost function ρ n (x n , y n ) that models the cost of wrong assignments, i.e., assigning an estimated infection status y n to the n-th individual with actual infection status x n . In contrast to communication scenarios where 0 and 1 are usually interchangeable, the cost ρ n (0, 1) of false positive assignment (i.e., a healthy individual is wrongly assigned an infected status) is not necessarily the same as the cost ρ n (1, 0) of a false negative assignment (i.e., an infected individual is wrongly assigned a healthy status). Thus, we define ρ n (0, 1) = b n , andwhere b n , c n > 0. The cost of correct assignments is set to zero, i.e., ρ n (0, 0) = ρ n (1, 1) = 0 and the total cost ρ : Ω N ×Ω N → R is given by summation (x, y) → ρ(x, y) = N n=1 ρ n (x n , y n ). We now turn to the mathematical description of testing strategies. A testing strategy for N individuals consists of a test procedure and a decision procedure. An (N, K)-test procedure is given by η = (η 1 , η 2 , . . . , η K ) where η 1 ∈ P {1, 2, . . . , N } and for k > 1, η k : Ω k−1 → P {1, 2, . . . , N } , where P {1, 2, . . . , N } denotes the collection of all subsets of {1, 2, . . . , N }. Here, the set η 1 indicates the group used for the first test and the set-valued function η k indicates the group used for the k-th test, given the results of the previous k − 1 tests. The corresponding test function ϑ : Ω N → Ω K is given by ϑ 1 (x) = max{x n |n ∈ η 1 } and for k > 1, we have ϑ k (x) = max x n n ∈ η k ϑ 1 (x), ϑ 2 (x), . . . , ϑ k−1 (x) . Thus, the k-th component ϑ k corresponds to the result of the k-th test.A (K, N )-decision procedure is a mapping κ : Ω K → Ω N that assigns, based on the outcome of K tests, a status (infected/healthy) to all N individuals.The concatenation of ϑ and κ maps the true status X := (X 1 , . . . , X N ) of all N individuals to an estimated status (Y 1 , . . . , Y N ) = κ ϑ(X 1 , . . . , X N ) of these individuals using K group tests. In total, this corresponds to R = K/N tests per individual (TpI) which is referred to as the rate of the testing strategy. If R < 1, which is the regime we are interested in, there is a positive probability that the tests will not enable a perfect identification of all infected individuals. Note that such an estimate (0: not infected, 1: infected) has to be given for all N individuals. We do not allow for individuals to be "skipped," which would correspond to a ternary output alphabet.To assess the average cost of the wrong assignments for given test and decision procedures, we use the expected cost per individual, defined as the expected valueBecause there are only finitely many possible choices for ϑ and κ, we can define the minimum D (X,ρ) (K) = minwhere ϑ and κ range over all (N, K)-test and (K, N )-decision procedures, respectively. The quantity D (X,ρ) (K) specifies the minimal cost, measured by ρ, that can be achieved by using K tests for the N individuals with random infection status X.

Results

Calculating D (X,ρ) (K) directly from (3) is computationally infeasible, unless N and K are very small. Nevertheless, we can use information-theoretic ideas to provide bounds. These bounds are based on the idea of keeping the rate R = K/N fixed, while letting N approach infinity. Our first result is a lower bound, that holds if all individuals share the same parameters. Here, and in the remainder of the paper, we use the symbol H 2 (p) = −p log p − (1 − p) log(1 − p) for the binary entropy function, log( · ) denotes the logarithm to base 2, and we adopt the convention that "0 · log 0 = 0." The proofs of the results in this section are presented in Section 5 and in the appendices.The following theorem presents a lower bound on D (X,ρ) (K) for the case when infection is equally likely and independent across the entire population.It follows immediately from the more general Theorem 3.6, which will be stated later in this section.Theorem 3.1. Let X := (X 1 , . . . , X N ) be N independent and identically distributed Bernoulli(p) random variables describing the infection status of a given population. The cost of wrong assignments is given by (1) with b n = b and c n = c for all n. Furthermore, set a :andThen there cannot exist a testing strategy that uses fewer thanR(p, a, v) TpI (i.e.,R(p, a, v)N tests in total) and achieves an expected cost less than bD(p, a, v), i.e., D (X,ρ) (K) ≥ bD(p, a, v) for all K ≤R(p, a, v)N .We emphasize that, in contrast to similar results in classical information theory, the lower bound in Theorem 3.1 cannot always be achieved arbitrarily closely for increasing N . For example, for p = 1 2 (3 − √ 5) ≈ 0.381 and v = 0, we obtainD(p, a, v) = 0 andR(p, a, v) = H 2 (p) ≈ 0.959, although it is known [23] that only individual testing (i.e., R = 1) can achieve D (X,ρ) (K) = 0 in this setting.Even though the lower bound in Theorem 3.1 is somewhat cumbersome and difficult to grasp intuitively, it can easily be calculated for a given scenario. We will compare it to proposed testing strategies in Figure 1 to illustrate its applicability.We next calculate the necessary number of tests and the resulting cost for some simple testing strategies. We first consider the strategy, proposed by Jonnerby et al. [22] , to separate the population into equally sized and disjoint groups, test each group, and assign an infected status to each member of a positive group without conducting further tests. We refer to this strategy as one stage group testing (1SG) and designate the size of the group in parenthesis, e.g., 1SG(50) for a group size of 50 individuals. We restate the following simple result from Section 2.3.1 in Jonnerby et al. [22] , which is a special case of the more general Lemma 3.4 below.Lemma 3.2. The 1SG(u) testing strategy has a rate of 1/u TpI and an expectedNote that the exact rate and expected cost can be achieved only for a population N that is an integer multiple of the group size u. However, the overhead is at most 1 additional test for a final group of smaller size, resulting in an additional 1/N TpI and a negligible decrease of the expected cost. Since we are usually concerned with large N , we ignore these terms in this and the following testing strategies. Of course, 1SG(u 1 ) can be further extended by testing those individuals again, that belong to a positively tested group of size u 1 . Specifically, we can separate the group into disjoint subgroups of smaller size u 2 and subject these subgroups again to a group test. This two stage group testing (2SG) strategy is a generalization of Dorfman testing [1] which corresponds to the case u 2 = 1, i.e., each individual in a positive group is tested separately. The decision strategy remains the same as in 1SG: Those individuals that belong to a positively tested subgroup (of size u 2 ) are declared infected. We again designate the group sizes in parenthesis, e.g., 2SG(50, 10) for a group size of 50 individuals that is divided into five subgroups of 10 individuals each, if the first group test is positive. Again, we can calculate the rate and expected cost in closed form.and an expected cost per individual ofEvidently, more than 2 stages could be used, but even more bookkeeping is then required and, typically, very large group sizes are needed to obtain a benefit. Thus, this extension may not be practically useful anymore. For the sake of completeness, we nevertheless provide the rate and expected cost of k stage group testing, abbreviated as kSG(u 1 , . . . , u k ), where u ℓ denotes the group size at stage ℓ. Here, positive groups of size u ℓ are separated into smaller subgroups of size u ℓ+1 for ℓ = 1, . . . , k − 1 and individuals that belong to a positive subgroup at stage k are declared infected, while all others are declared healthy. A proof of the result is given in Appendix C.Lemma 3.4. The kSG(u 1 , . . . , u k ) testing strategy has an expected rate ofand an expected cost per individual ofExample 3.5. We consider the setting p = 0.01, b = 1, and c = a = 50, i.e., we assume that we have a prevalence of 1% and a false negative is fifty times worse than a false positive assignment. We begin with some trivial observations. First, if we do not have any tests available, the best strategy is to assign everyone to be healthy. This is because the expected cost of declaring an individual healthy is E ρ(X n , 0) = p · a + (1 − p) · 0 = 0.5, while the expected cost for declaring someone infected is E ρ(X n , 1) = p · 0 + (1 − p) · 1 = 0.99. On the other extreme is the case of zero cost, i.e., to determine exactly which individuals are infected. Here, clearly individual testing at a rate of 1 TpI could be applied, but Theorem 2 in Aldridge [9] shows that it is also possible using a binary splitting algorithm at a rate of 0.0855 TpI. Any rate-cost tradeoff between these extreme points can be achieved by applying the available tests to as many individuals as possible, while declaring all others as healthy by default. Unfortunately, using approaches like a binary splitting algorithm do not come without problems: There is a significant amount of bookkeeping required and individuals usually have to be tested many times in a row delaying the notification about the result. Shifting to the strategies 1SG and 2SG that do not aim at identifying the status of each individual but to minimize the overall expected cost can lead to simpler procedures and better performance at the same time. Our lower bound in Theorem 3.1, the binary splitting algorithm, and the strategies 1SG and 2SG, as well as individual testing, for comparison, are illustrated in Figure 1 . Note, that for all strategies, one can always subject only part of the individuals to a test and simply declare the rest healthy. In particular, we see that the optimal 2SG strategy when tests are scarce (less than 0.037 TpI) is to use the testing strategy 2SG(66, 22) for as many individuals as possible, outperforming the binary splitting approach.The example above illustrates that the proposed strategies, although very simple, can outperform the best known testing strategies if there are not sufficient tests available to test all individuals. This is because previous strategies always aimed at exactly identifying the infection status and did not consider the possibility to declare an infection status based on imperfect information. However, there are also many situations where the simple strategies we discussed above are useless. In particular, if the relative cost a is small, then it is hardly ever useful to declare an individual infected if one is not very sure about the infection status.We now turn to the more general setting of a heterogeneous population, i.e., individuals may have different prevalence p n and also different costs b n and c n . One simple example of this situation is to distinguish between individuals with symptoms (that have a higher prevalence p n ) and individuals without symptoms. Additionally, different costs may occur for individuals in critical areas, e.g., health care. There, a higher risk of infecting vulnerable individuals may increase the cost c n of false negatives, and additionally, a higher false positive cost b n might be incurred due to the importance of the work being performed by these individuals. We will discuss a specific scenario in Section 4 but first present the lower bound, an extension of Theorem 3.1. The proof of the following theorem will be presented at the end of Section 5, as it requires several results from rate-distortion theory which are introduced there. whereD(p, a, v) andR(p, a, v) are defined in Theorem 3.1. Then there cannot exist a testing strategy that uses fewer than R(v) TpI (i.e., R(v)N tests in total) and achieves an expected cost less than

Historic example case

We consider the SARS-CoV2 pandemic situation in Austria in mid November 2020. On average there were N = 8 916 845 individuals living in Austria in 2020 [24] . During the three days from 12th of November 2020 until 14th of November 2020 a total of N t = 103 621 individuals were subjected to a PCR-test for SARS-CoV2 [25] . Of these N t individuals, 20 349 tested positive [25] . This corresponds to a prevalence of p t = 0.196 in this tested subpopulation. We will refer to this subpopulation as the high prevalence subpopulation. At the same time, a prevalence study found that approximately 3.1% of the total population were infected [26] . Thus, in the untested population of N u = 8 813 224 the prevalence was about p u = 0.029. We will refer to this subpopulation as the low prevalence subpopulation.To illustrate the full potential of our model, we further consider individuals working in health care separately and will assign a higher cost for wrong assignments within this subpopulation. The most recent count of health care professionals working in hospitals and health care centers in Austria was N h = 121 567 at the end of 2019 [27] . Note that a finer separation into subpopulations is of course possible but avoided for the sake of simplicity.It is difficult to argue for the choice of specific costs of wrong assignments. However, in mid November 2020, a lockdown was issued in Austria, 1 which we interpret as the turning point where considering all (untested) individuals as infected is less costly than considering these individuals as healthy. This implies (1 − p)b ≈ pc, thus, at a prevalence of p = 0.029 in the untested, general population, we obtain c ≈ 33b. We normalize b = 1 and choose c = 33. Since health-care facilities were not closed during this time, we assume that individuals working in health care have a different trade-off between b and c. Specifically, we assume that a false positive assignment for this subpopulation is significantly more expensive and we set b = 6 for these individuals. Although also a different c value could be argued, we assume that the professional training counters the higher risk due to closer contact with susceptible individuals and we keep c the same.Since there is no data available on the prevalence within the health care system, we assume that it is the same as in the general population. In particular, also the split into the high prevalence and low prevalence subpopulations is assumed to be the same. We thus end up with the following four subpopulations • The first subpopulation consists of individuals working in health care that belong to the high prevalence subpopulation with p (1) = 0.196 and costs b (1) = 6, c (1) = 33. We assume that N (1) = 1 413 belong to this subpopulation.• The second subpopulation consists of individuals working in health care that belong to the low prevalence subpopulation with p (2) = 0.029 and costs b (2) = 6, c (2) = 33. We assume that N (2) = 120 154 belong to this subpopulation.• The third subpopulation consists of individuals not working in health care that belong to the high prevalence subpopulation with p (3) = 0.196 and costs b (3) = 1, c (3) = 33. We assume that N (3) = 102 208 belong to this subpopulation.• The fourth subpopulation consists of individuals not working in health care that belong to the low prevalence subpopulation with p (4) = 0.029 and costs b (4) = 1, c (4) = 33. We assume that N (4) = 8 693 070 belong to this subpopulation.Our lower bound and the performance of the optimal combinations of 1SG and 2SG strategies for these specific parameters are illustrated in Figure 2 in comparison to optimized binary splitting algorithms and individual testing. More specifically, the depicted curves correspond to the optimal use of the available tests under the given strategy. For individual testing and the binary splitting algorithms, this means that depending on the number of tests, a certain amount of people can be tested and correctly informed about their status, while many untested individuals remain and are assigned a status without being tested resulting in the depicted cost.For the 103 621 tests used during the discussed period, which correspond to 0.0116 TpI, the optimized strategy is to subject as many individuals from the fourth subpopulation as possible to a test using a 1SG(33) testing strategy. By this approach, the expected cost is 0.816. Individual testing could only reduce the expected cost to 0.944, hardly any improvement over not testing at all at an expected cost of 0.956. Note that in all subpopulations and strategies we assume that an optimal decision for untested individuals is used, namely, that a healthy status is assigned to untested individuals in subpopulations two and four and an infected status to untested individuals in subpopulations one and three.To illustrate the implications of this kind of strategy, we calculate the expected number of individuals that are considered infected. First, this number (2)(∞)(∞) (14) (2)(∞)(∞) (30, 10) (2)(10, 2)(∞) (27, 9) (3, 1)(10, 2)(∞)(21, 7)(3, 1)(6, 1)(5) (15, 5) (3, 1)(6, 1)(2)(12, 3)Tests per 100 000 individuals

Cost per individual

Individual Testing 1SG/2SG Binary Splitting Lower Bound Figure 2 : Testing of the Austrian population grouped into 4 different sub-populations in mid November 2020. The lower bound from Theorem 3.6 is compared to the binary splitting algorithm, and an optimal combination of strategies 1SG and 2SG as well as the significantly worse individual testing. Markers with associated numbers indicate the four testing strategies used to achieve the given point, where ∞ indicates that the given subpopulation is not tested, e.g., (2)(∞)(∞) (30, 10) indicates that subpopulations 2 and 3 are not tested, subpopulation 1 is tested using 1SG (2) , and subpopulation 4 is tested using 2SG (30, 10) .includes all individuals in the subpopulations one and three. Furthermore, each 1SG(33) test in subpopulation four has a probability of 1 − (1 − 0.029) 33 ≈ 0.621 to result in a positive outcome. Thus, an additional expected number of 2 124 712 individuals would be considered infected in this subpopulation. In total, an expected number of 2 228 333 individuals would be considered infected. We see that the decrease in expected cost is very limited with such a low number of tests, even if an optimized strategy is used. In particular, our lower bound shows that no strategy can reduce the expected cost below 0.609 using the assumed 103 621 tests. However, our theory can also be used to estimate how many tests are required to achieve a certain reduction in expected cost. For example, we can find the number of tests necessary to obtain half the expected cost than without testing, i.e., 0.478. Our lower bound shows that at least 0.0226 TpI (201 256 tests in total) are necessary, while our optimized strategies show that 0.0419 TpI (373 636 tests in total) are sufficient. Our optimized strategies suggest to use a 1SG(4) strategy to test all individuals in subpopulation one and a mix of 1SG(24) and 1SG (23) strategies to test all individuals in subpopulation four. We also want to point out that an astonishing number of 0.499 TpI (4 447 461 tests in total) would be required to achieve the same goal with individual testing; and even the previously best known binary splitting testing strategies require 0.102 TpI (909 637 tests in total).A second example case is presented in Appendix A, analyzing the situation in Austria during the SARS-CoV-2 pandemic in early April 2020. The two examples showcase how our theory can be used to explore possible strategies for a given set of parameters and a given number of tests. Furthermore, they already illustrate that the specific scenario can affect all parts of the optimal testing strategy, e.g., there is no general rule that the testing of individuals with highest prevalence has priority. Maybe surprisingly, the examples also illustrate that there are situations where our approach can result in substantial gains using very simple testing strategies. Any other parameter choices can be explored using the Jupyter notebook and Python code, available at https://github.com/g-pichler/group-testing. This software was created using a Jupyter Notebook [28] , as well as SciPy [29] , NumPy [30] , and Matplotlib [31] .Finally, we want to emphasize, that the historic example cases discussed here certainly do not completely reflect the reality of testing in Austria in 2020. In addition to the somewhat arbitrary choices of values b, c, our analysis suffers from the shortcomings that are to be discussed in Section 6. E.g., considering the first example case (Figure 2 ), a 1SG(33) test is positive with probability around 0.621, while the chance of infection is less than 0.03. One would not expect this strategy to be viable, as compliance will be low.

Information theoretic details

Readers familiar with information theory will see the obvious analogues between our problem formulation and classical rate-distortion theory [32] . Indeed, an (N, K)-test function can be seen as a specific encoder of a binary sequence, whereas the corresponding (K, N )-decision procedure is a specific decoder. Thus, D (X,ρ) (K) defined in (3) is the minimal expected distortion of a restricted class of source codes of rate R = K/N for the vector X.A fundamental information-theoretic result provides a lower bound on the minimal expected distortion of an arbitrary source code of rate R, the so-called information distortion-rate function.Definition 5.1. Let X be a random variable on Ω N and ρ : Ω N × Ω N → R + a distortion function. The information distortion-rate function of (X, ρ) is given bywhere I( · ; · ) denotes mutual information in bits [32, Sec. 2.6] .Because D (X,ρ) I (R) is a lower bound on the minimal expected distortion of an arbitrary source code of rate R, it can be used to obtain a lower bound on D (X,ρ) (K). The following lemma is a direct consequence of Theorem 3.2.1 in [32] and a proof is thus omitted. To prove our main results, it remains to characterize the information distortion-rate function D (X,ρ) I (R). We first focus on the case N = 1 and will subsequently extend our setting to prove Theorem 3.6. The following result is based in the variational description of the information distortion-rate function (see Section 2.4 in Gray [32] ) and a detailed proof is provided in Appendix B.1. We can now state the central characterization result of the information distortion-rate function in the setting of Theorem 3.6. A detailed proof of the result is provided in Appendix B.2.Theorem 5.5. Let X be as in Theorem 3.6. Then D (X,ρ) Iand R(v) are given in (9) .Combining the previous results, we can now prove Theorems 3.1 and 3.6.Proof of Theorems 3.1 and 3.6. By Lemma 5.2, we have for all R ≥ 0, thatUsing the characterization of the information distortion-rate function in Theorem 5.5, this yields D (X,ρ) (K) ≥ D(ν) whenever K ≤ N R(ν), concluding the proof of Theorem 3.6.Theorem 3.1 is merely a special case of Theorem 3.6 with I = 1.Finally, we want to point out that many information theoretic questions about the problem remain open. In particular, the characterization of a "group testing distortion-rate function" that can be defined as the infimum of all expected distortions that are achievable at a given rate as the population size N goes to infinity is a challenging new problem that can also be formulated as a problem in classical rate-distortion theory with significant restrictions on the encoder. Here, non-adaptive group testing may be easier to analyze because the encoder is essentially restricted to the max( · ) function. Another direction for future work is to incorporate testing errors, resulting in a joint source-channel coding scenario. It is not clear whether the source-channel separation theorem holds in this case. Nevertheless, we expect that a lower bound similar to the one presented here can be obtained, by adding the additional bits (i.e., tests) necessary for error-free communication over a binary (most likely asymmetric) channel.

Discussion

We introduced a rigorous mathematical formulation of optimal testing strategies for a given number of available group tests. The problem is formulated as a one-time testing procedure in the sense that we assume that the infection status of the population does not change during the testing procedure and we do not consider any time evolution. This enables us to use only very few parameters that describe a current pandemic situation and we do not require any detailed personal information such as contact maps between individuals. However, even these few parameters can be difficult to estimate and may also result in ethical challenges. The prevalence p is the easiest and most obvious parameter and can be estimated using a negligible number of tests for a pilot study and the estimate can be improved as the testing strategy is applied. The costs b and c of wrong assignments are more difficult to choose. They can be adapted to the infectiousness of the disease, the cost and effectiveness of quarantine, non-pharmaceutical interventions that reduce the risk of infection, and most likely many more variables. How to exactly choose these costs is beyond the scope of our work and very specific for a given situation. It may also include political decisions by weighing health factors (e.g., minimize the number of infections by quarantining many individuals) against economic factors (e.g., minimize the number of quarantined individuals). Note however that at least implicitly these costs are used in political decisions: A society-wide lockdown can be interpreted as the assertion, that assigning all (untested) individuals an infected status is less costly than considering them to be healthy. Thus, at a prevalence p, this implies (1 − p)b ≤ pc.Once the parameters are fixed for a given scenario, our theory on the one hand gives ultimate bounds on how large a cost reduction can be achieved by group testing, and on the other hand suggests optimal allocation of resources for simple (suboptimal) testing strategies.The present work is only a first step towards establishing a mathematical theory of group testing. Thus, we do not consider the most general scenario and focus on basic scenarios that are simplified in many aspects. In particular, the scope of our results is limited by the following assumptions:• We assume that tests are perfect, i.e., a group test of u individuals is negative if and only if all u individuals are healthy. However, we expect that a small error probability will not significantly influence the results and simple simulations incorporating these errors can be used to check the robustness in a specific scenario. A rigorous theoretical treatment on the other hand should not only consider a fixed error probability for a group test, but the error probability should rather depend on the group size and the number of infected individuals within the group (cf. Pilcher et al. [18] ). Thus, an extension of our work in this direction would imply a more quantitative approach of testing outcomes and not merely the binary options we consider here.• In this work, no upper bound on the group size is assumed a priori. The information theoretic lower bounds would not be affected by such a limitation, but certain points of the kSG strategy will become infeasible, requiring minor modifications to the published code. However, a more thorough analysis would not impose a hard limit on the group size, but consider the trade-off between test accuracy and group size, as mentioned in the previous point.• We assume that the infection status of different individuals is independent.• We assume that the choice of testing strategy does not alter the cost of wrong assignment. This assumption may be violated in reality, as e.g., individuals that are assigned an "infected" will likely show different levels of compliance, depending on whether they were tested individually, in a group, or not at all. Going beyond this assumption could be achieved by changing the infection status from a binary decision to a probability assignment and using a suitably adapted cost function.• The cost function is fixed and applied independently to each individual. E.g., we cannot express the fact, that quarantining a small number of individuals working in critical areas is hardly problematic but once a critical threshold is passed the cost of quarantining further individuals becomes more costly than the linear increase assumed in our model.• We do not consider the collection of samples from individuals as a limiting factor, but merely the number of tests is limited.• The testing strategies presented in this work are not at all optimal but merely illustrate the potential of our approach. For example, we do not consider testing individuals in several groups at the first stage (as, e.g., in the array testing approach by Phatarfod and Sudbury [8] ), nor mixing individuals from different subpopulations within a group. Nevertheless, our suggested strategies are surprisingly simple and can outperform even the best (significantly more complicated) strategies currently known.• We consider testing as a stand-alone task and do not incorporate it into a larger disease model, as is done, e.g., in Berger et al. [33] . In particular, the probabilities of infection and the cost functions are assumed to be fixed and do not change over time.From a theoretical viewpoint, our analysis reveals several surprising insights that are in contrast to long established fundamental statements in group testing theory. First, an established statement is that group testing is beneficial exactly in the regime p < 1 2 (3 − √ 5) ≈ 0.381 [23] , i.e., in this regime, group testing cannot outperform individual testing. However, this result was proven under the assumption that perfect identification of the infection status of each individual is required. Maybe surprisingly, this statement does not extend to our setting. Indeed, for the specific case of p = 1 2 (3 − √ 5), b = 1, and c = 10, using the testing strategy 1SG(2) has a strictly lower expected cost than individually testing every second individual (both have rate 1/2 TpI). Similarly, in the nonadaptive regime (i.e., all tests are performed in parallel) an established result is that individual testing is optimal if all individuals are independent and have a fixed prevalence p [34] . Again, this result only holds if perfect identification of the infection status of each individual is required. In our setting, the simple 1SG testing strategy is a non-adaptive strategy and is clearly superior to individual testing (see Figure 1 ).

A. Second example case

As a second example with significantly different prevalences, we consider the SARS-CoV2 pandemic situation in Austria in early April 2020. More specifically, another prevalence study was conducted from 1st of April until 6th of April 2020. Here, a prevalence of approximately p = 0.0033 was found [35, Section 3.2] . Since most of the samples were collected on the 4th of April, we consider a timeframe from 3rd of April until 5th of April. On these three days a total of N t = 16 226 tests were conducted [25] . Of those, 778 did yield a positive result [25] . Thus, the prevalence in this high prevalence subpopulation was p t = 0.048. The resulting untested population is N u = 8 900 619 with a prevalence of p u = 0.0032. We consider the same separation into subpopulations as before as well as the same costs.• The first subpopulation consists of individuals working in health care that belong to the high prevalence subpopulation with p (1) = 0.048 and costs b (1) = 6, c (1) = 33. We assume that N (1) = 221 belong to this subpopulation.• The second subpopulation consists of individuals working in health care that belong to the low prevalence subpopulation with p (2) = 0.0032 and costs b (2) = 6, c (2) = 33. We assume that N (2) = 121 346 belong to this subpopulation.• The third subpopulation consists of individuals not working in health care that belong to the high prevalence subpopulation with p (3) = 0.048 and costs b (3) = 1, c (3) = 33. We assume that N (3) = 16 005 belong to this subpopulation.• The fourth subpopulation consists of individuals not working in health care that belong to the low prevalence subpopulation with p (4) = 0.0032 and costs b (4) = 1, c (4) = 33. We assume that N (4) = 8 779 273 belong to this subpopulation. 6 is compared to the binary splitting algorithm, and an optimal combination of strategies 1SG and 2SG as well as the significantly worse individual testing. Markers with associated numbers indicate the four testing strategies used to achieve the given point, where ∞ indicates that the given subpopulation is not tested, e.g., (8, 2)(∞)(18, 6)(72, 12) indicates that subpopulation 2 is not tested and subpopulations 1, 3, and 4 are tested using 2SG (8, 2) , 2SG (18, 6) , and 2SG(72, 12), respectively.Our lower bound and the performance of the optimal combinations of 1SG and 2SG strategies for these specific parameters are illustrated in Figure A. 3. For the 16 226 tests used during the discussed period, which correspond to 0.0018 TpI, the optimized strategy is to subject all individuals in subpopulation one to a test using a 2SG (8, 2) testing strategy, all individuals in subpopulation three using a 2SG (18, 6) testing strategy, and as many individuals from the fourth subpopulation as possible using a 2SG(72, 12) testing strategy. Using this approach yields an expected cost of 0.1023. Individual testing could only reduce the expected cost to 0.1054, while not testing at all results in an expected cost of 0.1072.

B. Proofs of information theoretic results

In this appendix, we provide detailed proofs of the two main information theoretic results in the main manuscript, namely Theorem 5.3 and Theorem 5.5.

B.1. Proof of Theorem 5.3

The following variational description of the information distortion-rate function is a particularization of Corollary 4.2.1 in Gray [32] to our setting of binary random variables with an asymmetric distortion function, substituting v = 2 s . andwhere q * solves the minimization in (B.1).The minimization in (B.1) can easily be done exactly. Although one could use existing results, e.g., Theorem 4.2.3 in Gray [32] , it is easier to derive the optimization directly than to particularize these general results.Lemma B.2. For v, p ∈ (0, 1) and a > 0, the function φ : [0, 1] → R defined byis convex and arg minProof. The derivative of φ is given as.Thus, φ ′ (q) = 0 if and only ifwhich is equivalent toand in turn to q = q v . The second derivative is given aswhich is positive and thus φ is convex. Thus, if the critical value q v is in (0, 1) then it is the global minimum. Otherwise, q v ≥ 1 implies φ ′ (q) < 0 on (0, 1) and thus the global minimum is at 1, and q v ≤ 0 implies φ ′ (q) > 0 on (0, 1) and thus the global minimum is at 0. We first show that q v ∈ (0, 1) (i.e., the first case in (B.4)) if and only if v ∈ (0, v 0 ). By the definition of q v in (B.5), q v > 0 is equivalent toand q v < 1 is equivalent to (B.14)Next, we note thatandInserting these relations into D v in (B.2), simple algebraic manipulations yield D v =D(p, a, v) . Similarly, inserting the relations into (B.1), we obtain R v = R(p, a, v).On the other hand, consider the case v ∈ [v 0 , 1). Assuming f (v 0 ) = 0, we must have f ′ (1) ≥ 0, which is equivalent to 1 − p ≤ ap. Furthermore, v lies between two zeros of a convex function and is thus nonpositive, i.e., (B.13) is not satisfied. Thus, q v ≥ 1, which in turn yields R v = 0 =R(p, a, v) andFinally, observing that the case v ∈ {0, 1} follows by continuity concludes the proof of Theorem 5.3.

B.2. Proof of Theorem 5.5

We first establish a general result for the joint information distortion rate function of several independent sources particularized to the setting of Theorem 5.5. We will use the shorthand D n I = D = minProof. In (10), the right-hand side can be rewritten asE pX n p Yn |Xn ρ n (X n , Y n ) .

(B.19)

Furthermore, we can expand the mutual information asH(X n ) − H(X n | Y, X 1 , . . . , X n−1 )with equality if p Y|X (y|x) = n p Yn|Xn (y n |x n ). We can thus restrict the minimization in (B.19) to p Y|X (y|x) = n p Yn|Xn (y n |x n ) and obtain Note that the only difference between (B.17) and (B.18) is that all ξ n for X n belonging to the same subpopulation are chosen to be equal, i.e., ξ n = ξ (i) . To justify this choice, we have to show that this indeed minimizes the sum, i.e., N (i) D Recall that we actually want to solve the minimization problem for a given v at the fixed R , we obtain from the definition ofR(p (i) , a (i) , v b (i) ) that ξ (i) = 0. According to Remark 5.4, the derivativeḊ log v which is nonnegative due to v b (i) ≥ v (i) 0 and thus (B.28) is satisfied.and µ (i) = 0 otherwise, satisfy the KKT conditions. The equations (9) then follow by inserting ξ (i) N R = R(p (i) , a (i) , v b (i) ) into D (i) I (ξ (i) N R) and noting that, by Theorem 5.3, we have D (i) I (R(p (i) , a (i) , v b (i) )) = b (i)D (p (i) , a (i) , v b (i) ).

C. Evaluation of k stage group testing

To calculate the expected rate, we denote by T ℓ the TpI used in the ℓ-th stage of the testing procedure. Then Since in the first stage all individuals are tested in groups of size u 1 , the expectation is simply E[T 1 ] = 1 u1 . In the (ℓ + 1)-th stage for ℓ ≥ 1 only those individuals that belong to groups of size u ℓ including at least one positive individual are tested. We can thus condition the expectation on the event that the group of size u ℓ the individual belongs to is negative, which has probability (1 − p) u ℓ , or positive, which has probability 1 − (1 − p) u ℓ . Hence, the expectation expands toconcluding the proof of (7). To prove (8), first note that kSG(u 1 , . . . , u k ) never declares an infected individual as healthy. Indeed, the only cases of wrong assignment can happen in groups that are positive at the k-th stage. Here, all individuals in the group are declared infected, although there may be several healthy individuals in the group. Thus, the expected cost of a single individual is the probability of itself being negative times the probability that at least one of u k − 1 other individuals is infected times the false positive cost b, i.e., 

