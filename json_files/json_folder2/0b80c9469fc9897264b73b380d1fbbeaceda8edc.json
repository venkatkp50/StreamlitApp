{
    "paper_id": "0b80c9469fc9897264b73b380d1fbbeaceda8edc",
    "metadata": {
        "title": "Vector mosquito image classification using novel RIFS feature selection and machine learning models for disease epidemiology",
        "authors": [
            {
                "first": "Furqan",
                "middle": [],
                "last": "Rustam",
                "suffix": "",
                "affiliation": {
                    "laboratory": "",
                    "institution": "Khwaja Fareed University of Engineering and Information Technology",
                    "location": {
                        "addrLine": "Rahim Yar Khan 64200",
                        "country": "Pakistan"
                    }
                },
                "email": ""
            },
            {
                "first": "Aijaz",
                "middle": [
                    "Ahmad"
                ],
                "last": "Reshi",
                "suffix": "",
                "affiliation": {
                    "laboratory": "",
                    "institution": "University of North Texas",
                    "location": {
                        "settlement": "Denton",
                        "region": "TX",
                        "country": "USA"
                    }
                },
                "email": ""
            },
            {
                "first": "Wajdi",
                "middle": [],
                "last": "Aljedaani",
                "suffix": "",
                "affiliation": {},
                "email": ""
            },
            {
                "first": "Abdulaziz",
                "middle": [],
                "last": "Alhossan",
                "suffix": "",
                "affiliation": {
                    "laboratory": "",
                    "institution": "King Saud University",
                    "location": {
                        "postCode": "11451",
                        "settlement": "Riyadh",
                        "country": "Saudi Arabia"
                    }
                },
                "email": ""
            },
            {
                "first": "Abid",
                "middle": [],
                "last": "Ishaq",
                "suffix": "",
                "affiliation": {
                    "laboratory": "",
                    "institution": "Khwaja Fareed University of Engineering and Information Technology",
                    "location": {
                        "addrLine": "Rahim Yar Khan 64200",
                        "country": "Pakistan"
                    }
                },
                "email": ""
            },
            {
                "first": "Shabana",
                "middle": [],
                "last": "Shafi",
                "suffix": "",
                "affiliation": {
                    "laboratory": "",
                    "institution": "University of North Texas",
                    "location": {
                        "settlement": "Denton",
                        "region": "TX",
                        "country": "USA"
                    }
                },
                "email": ""
            },
            {
                "first": "Ernesto",
                "middle": [],
                "last": "Lee",
                "suffix": "",
                "affiliation": {
                    "laboratory": "",
                    "institution": "Broward County",
                    "location": {
                        "region": "FL",
                        "country": "USA"
                    }
                },
                "email": ""
            },
            {
                "first": "Ziyad",
                "middle": [],
                "last": "Alrabiah",
                "suffix": "",
                "affiliation": {
                    "laboratory": "",
                    "institution": "King Saud University",
                    "location": {
                        "postCode": "11451",
                        "settlement": "Riyadh",
                        "country": "Saudi Arabia"
                    }
                },
                "email": ""
            },
            {
                "first": "Hessa",
                "middle": [],
                "last": "Alsuwailem",
                "suffix": "",
                "affiliation": {
                    "laboratory": "",
                    "institution": "King Saud University",
                    "location": {
                        "postCode": "11451",
                        "settlement": "Riyadh",
                        "country": "Saudi Arabia"
                    }
                },
                "email": ""
            },
            {
                "first": "Ajaz",
                "middle": [],
                "last": "Ahmad",
                "suffix": "",
                "affiliation": {
                    "laboratory": "",
                    "institution": "King Saud University",
                    "location": {
                        "postCode": "11451",
                        "settlement": "Riyadh",
                        "country": "Saudi Arabia"
                    }
                },
                "email": ""
            },
            {
                "first": "Vaibhav",
                "middle": [],
                "last": "Rupapara",
                "suffix": "",
                "affiliation": {
                    "laboratory": "",
                    "institution": "Florida International University",
                    "location": {
                        "country": "USA"
                    }
                },
                "email": ""
            },
            {
                "first": "Al",
                "middle": [],
                "last": "Madinah",
                "suffix": "",
                "affiliation": {},
                "email": ""
            },
            {
                "first": "Al",
                "middle": [],
                "last": "Munawarah",
                "suffix": "",
                "affiliation": {},
                "email": ""
            },
            {
                "first": "Saudi",
                "middle": [],
                "last": "Arabia",
                "suffix": "",
                "affiliation": {},
                "email": ""
            }
        ]
    },
    "abstract": [
        {
            "text": "Every year about one million people die due to diseases transmitted by mosquitoes. The infection is transmitted to a person when an infected mosquito stings, injecting the saliva into the human body. The best possible way to prevent a mosquito-borne infection till date is to save the humans from exposure to mosquito bites. This study proposes a Machine Learning (ML) and Deep Learning based system to detect the presence of two critical disease spreading classes of mosquitoes such as the Aedes and Culex.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Abstract"
        },
        {
            "text": "The proposed system will effectively aid in epidemiology to design evidence-based policies and decisions by analyzing the risks and transmission. The study proposes an effective methodology for the classification of mosquitoes using ML and CNN models. The novel RIFS has been introduced which integrates two types of feature selection techniques -the ROI-based image filtering and the wrappers-based FFS technique. Comparative analysis of various ML and deep learning models has been performed to determine the most appropriate model applicable based on their performance metrics as well as computational needs. Results prove that ETC outperformed among the all applied ML model by providing 0.992 accuracy while VVG16 has outperformed other CNN models by giving 0.986 of accuracy.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Abstract"
        }
    ],
    "body_text": [
        {
            "text": "Every year mosquitoes cause notable damage to human populations as they spread deadly infectious diseases like yellow fever, malaria, encephalitis (Thomas et al., 2016) . It is supposed that half of the world's population is at risk of dengue fever, which also spreads by mosquitoes (W.H. Organization et al., 2020) . There is also solid evidence of an outbreak of combined infection of dengue and chikungunya pathogens in humans (Furuya-Kanamori et al., 2016) . For the age group of nine years and above a renowned vaccine Sanofi PasteurCYD-TDV for dengue shows its efficiency around 65.5% and for the age group under nine-year, its efficiency decreasesto 46.6% (Hadinegoro et al., 2015) . The major means of transmission of dengue, chikungunya, zika, and yellow fever include mosquitoes such as Aedes, Anopheles, and Culex (Roth et al., 2014; Jasinskiene et al., 1998) .",
            "cite_spans": [
                {
                    "start": 147,
                    "end": 168,
                    "text": "(Thomas et al., 2016)",
                    "ref_id": "BIBREF29"
                },
                {
                    "start": 289,
                    "end": 315,
                    "text": "Organization et al., 2020)",
                    "ref_id": "BIBREF30"
                },
                {
                    "start": 430,
                    "end": 460,
                    "text": "(Furuya-Kanamori et al., 2016)",
                    "ref_id": "BIBREF6"
                },
                {
                    "start": 663,
                    "end": 688,
                    "text": "(Hadinegoro et al., 2015)",
                    "ref_id": "BIBREF9"
                },
                {
                    "start": 825,
                    "end": 844,
                    "text": "(Roth et al., 2014;",
                    "ref_id": "BIBREF21"
                },
                {
                    "start": 845,
                    "end": 870,
                    "text": "Jasinskiene et al., 1998)",
                    "ref_id": "BIBREF12"
                }
            ],
            "ref_spans": [],
            "section": "Introduction"
        },
        {
            "text": "Mosquitoes are very small flying insects that have the ability to hide anywhere. Use of the pesticides and fogs has difficulty permeating into these hideouts. Mosquito nets show some ability to prevent them but this is not the perfect solution for decreasing the mosquitoes' proliferation. Entomological characterizations the basic tool for obtaining information about mosquitoes. Aedes and Culex are the two notorious types of mosquitoes. They are famous for spreading deadly diseases (W.H. Organization, 2021) . Aedes and Culex are common types of mosquitoes, which are present commonly in almost every part of the world under all suitable https://doi.org/10.1016/j.sjbs.2021.09.021 1319-562X/\u00d3 2021 The Author(s). Published by Elsevier B.V. on behalf of King Saud University. This is an open access article under the CC BY-NC-ND license (http://creativecommons.org/licenses/by-nc-nd/4.0/). weather conditions. Dengue fever is being spread by the Aedesalobopictus and Aedes Aegypti (T. center for disease control, 2021). On the other hand, Culex tritaeniorhychus and Culex annulus are infamous for the spread of Japanese Encephalitis (D. control center Taiwan, 2021) . While studying the works related to the diseases transmitted by the mosquitoes demands an efficient automatic system for the detection, and classification of the mosquitoes.",
            "cite_spans": [
                {
                    "start": 492,
                    "end": 511,
                    "text": "Organization, 2021)",
                    "ref_id": "BIBREF31"
                },
                {
                    "start": 1136,
                    "end": 1168,
                    "text": "(D. control center Taiwan, 2021)",
                    "ref_id": "BIBREF2"
                }
            ],
            "ref_spans": [],
            "section": "Introduction"
        },
        {
            "text": "To contribute to this important and critical disease spread domain, it demands an efficient automatic information system for the detection and classification of the special types of mosquitoes. The system will aid the health authorities and other stack holders to check the presence of any disease spreading mosquito in the area of their interest. The proposed system will effectively aid in epidemiology to design evidence-based policies and decisions by analyzing the risks and transmission. It will prepare the authorities to take preventive measures in the targeted areas to control its spread at the right time. This study proposes an effective methodology for the classification of mosquitoes using the deep learning approach.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Introduction"
        },
        {
            "text": "The dataset used in this study has been obtained from IEEE dataport contain to the type of mosquito images (Reshma Pise, 2020). The proposed system uses different techniques in data preprocessing to ensure the maximum classification performance as well as to explore the methods to classify the images using the lowest possible computational efforts. These preprocessing techniques include data augmentation and the proposed feature selection approach RIFS, a hybrid approach based on Image processing filters to focus on specific parts of an image which is significant in classification, and forward features selection (FFS) to select the best features from the ROI based RGB feature sets.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Introduction"
        },
        {
            "text": "As a first step towards preprocessing the data augmentation has been performed to increase the size of training data . After data augmentation, the feature selection has been done using the RIFS approach to select the specific features for the learning of models. The proposed machine learning (ML) and convolutional neural networks (CNN) have been used to learn on RIFS generated features. The performance of the models has been evaluated in terms of accuracy, precision, recall, and F1-score.",
            "cite_spans": [
                {
                    "start": 333,
                    "end": 338,
                    "text": "(CNN)",
                    "ref_id": null
                }
            ],
            "ref_spans": [],
            "section": "Introduction"
        },
        {
            "text": "The key points of the study are:",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Introduction"
        },
        {
            "text": "This study performs the classification of mosquitoes (Aedes and Culex) using ML and deep learning approaches. Data pre-processing has been done using data augmentation and the proposed novel feature selection technique RIFS which improves the performance and reduces the computational cost of the models A strong comparison has been done with the baseline pretrained and well-tuned models that have been done in this study Results show that ML models can also perform well in image classification if the datasets are preprocessed properly models are tuned well.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Introduction"
        },
        {
            "text": "The rest of the paper is divided into four sections. Section 2 contains the related work of the study, Section 3 contains the detailed description of the dataset, proposed methodology, and techniques. Section 4, contains the results of the experiments, Section 5 presents the discussion and Section 6 contains the conclusion of the study.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Introduction"
        },
        {
            "text": "Mosquito classification has gained much interest by researchers to work. Recent studies proposed different classification approaches, but efficiency and computational complexity are still a tradeoff in most of the research studies conducted so far. Several researchers have performed studies in this domain such as Garcia et al (Garcia et al.) . worked on the classification of mosquitoes larva. They used machine learning classifiers support vector machine (SVM) and K-means with low features like local binary pattern (LBP), co-occurrence matrix (CM), and Gabor filtering features (FG2). In their study, they used 308 images of ''Aedes\" and ''others\". Feature extraction was used for classification. The obtained results show that K-mean accuracy on low features and local binary pattern (LBP), co-occurrence matrix (CM), and Gabor filtered features (FG2) the Achieved accuracy was 59% for CM, 55% LBP, and 60% for the FG2. On the other hand, the accuracy achieved by the SVM was 67% for CM, 72% on LBP, and 79% for FG2.",
            "cite_spans": [
                {
                    "start": 328,
                    "end": 343,
                    "text": "(Garcia et al.)",
                    "ref_id": null
                }
            ],
            "ref_spans": [],
            "section": "Related work"
        },
        {
            "text": "Ortiz et al (Ortiz et al., 2018) . Proposed a system for mosquito larva classification by using a VGG16 pre-trained convolutional neural network. The dataset used in their work was consisting of two types of mosquitoes: Aedes and other genera. For training purposes, they used different values of epochs. Due to the pre-trained bottleneck features, they achieve the highest accuracy of 97%. Therefore, the localization of vectors could be accurate and the process of fumigation could be more efficient.",
            "cite_spans": [
                {
                    "start": 12,
                    "end": 32,
                    "text": "(Ortiz et al., 2018)",
                    "ref_id": "BIBREF16"
                }
            ],
            "ref_spans": [],
            "section": "Related work"
        },
        {
            "text": "In continuation of their work Ortiz et al(Sanchez-Ortiz et al., 2017) used AlexNet CNN for the classification of mosquitoes. They used images of eight segments of the larva. The images they have used in the study were obtained from the smart phone. They used nearly 300 images in their study. The number of iterations performed to increase the accuracy. On the 200 epochs, the proposed network achieved an accuracy of 96.8%.",
            "cite_spans": [
                {
                    "start": 30,
                    "end": 69,
                    "text": "Ortiz et al(Sanchez-Ortiz et al., 2017)",
                    "ref_id": "BIBREF22"
                }
            ],
            "ref_spans": [],
            "section": "Related work"
        },
        {
            "text": "Okayasci et al (Okayasu et al., 2019 )used(Sanchez-Ortiz et al., 2017 types of features in their work. They used handcrafted feature extraction and SVM for the classification. They built their dataset consisted of 14,460 images of mosquitoes with the three different types of mosquito species. This study compared the conventional and deep learning methods. Conventional methods provided the highest accuracy of 82.4% while the accuracy given by the deep learning model was 95.5% in the residual network using data augmentation. Data augmentation has been proved helpful for the classification of mosquito species.",
            "cite_spans": [
                {
                    "start": 15,
                    "end": 36,
                    "text": "(Okayasu et al., 2019",
                    "ref_id": "BIBREF15"
                },
                {
                    "start": 37,
                    "end": 69,
                    "text": ")used(Sanchez-Ortiz et al., 2017",
                    "ref_id": null
                }
            ],
            "ref_spans": [],
            "section": "Related work"
        },
        {
            "text": "Motta et al (Motta et al., 2019) used a convolutional neural network to perform automatic morphological classification of mosquitoes. They used LeNet, GoogleNet, and AlexNet in their study. By using GoogleNet, they achieved an accuracy of 76.2%. The dataset used in their studies consisted of 4056 images of mosquitoes. Li-Pang et al (Huang et al., 2018) worked on the automatic classification of mosquitoes which can identify Aedes and Culex (species of mosquitoes). They used edge computing and deep learning in their work. They implemented their system with the help of IoT-based devices. The highest accuracy they have achieved was 90.5% on test data.",
            "cite_spans": [
                {
                    "start": 12,
                    "end": 32,
                    "text": "(Motta et al., 2019)",
                    "ref_id": "BIBREF14"
                },
                {
                    "start": 334,
                    "end": 354,
                    "text": "(Huang et al., 2018)",
                    "ref_id": "BIBREF11"
                }
            ],
            "ref_spans": [],
            "section": "Related work"
        },
        {
            "text": "Fuchida et al (Fuchida et al., 2017) worked on vision-based perception and classification of mosquitoes. There proposed system has the capacity to identify mosquitoes from the other bugs (bees, flies) by extracting morphological features. They used the machine learning algorithm SVM variants in their work. SVM-II achieved an accuracy of 85.2% for mosquitoes and 97.6% for the bugs, and SVM-III achieved an accuracy of 98.9% for the mosquitoes and 92.5% for bugs.",
            "cite_spans": [
                {
                    "start": 14,
                    "end": 36,
                    "text": "(Fuchida et al., 2017)",
                    "ref_id": "BIBREF5"
                }
            ],
            "ref_spans": [],
            "section": "Related work"
        },
        {
            "text": "Fuad et al. (Fuad et al., 2018) classified Aedes Aegypti larvae and float value with three different learning rates. They have used 534 images in their study. They achieved the highest accuracy of 99%. They have compared the values of their accuracy and cross-entropy errors of the training set with the different learning rates. Minakshi et al. (Minakshi et al., 2017) proposed a learning algorithm that was designed to process the image of a mosquito taken by the mobile phone camera to identify the species of the mosquitos. The sample size was 60 images and seven species were used in their study. Random forest achieved the highest accuracy was 83.3% with good precision and recall value. As the dataset was of only 60 images so, it was not very suitable for classification.",
            "cite_spans": [
                {
                    "start": 12,
                    "end": 31,
                    "text": "(Fuad et al., 2018)",
                    "ref_id": "BIBREF4"
                },
                {
                    "start": 330,
                    "end": 369,
                    "text": "Minakshi et al. (Minakshi et al., 2017)",
                    "ref_id": "BIBREF13"
                }
            ],
            "ref_spans": [],
            "section": "Related work"
        },
        {
            "text": "Fahioudakis et al. (Fanioudakis et al., 2018) worked on a largescale classification experiment based on optical recordings of six different species of mosquitoes. They study the signal and attributes of a mosquito's wing beat. They have used 279,566 flight sound beats of mosquitoes and used top-tier deep learning approaches for the implementation of classification. They reached an accuracy of 96%.",
            "cite_spans": [
                {
                    "start": 19,
                    "end": 45,
                    "text": "(Fanioudakis et al., 2018)",
                    "ref_id": "BIBREF3"
                }
            ],
            "ref_spans": [],
            "section": "Related work"
        },
        {
            "text": "Akter et al. (Akter et al., 2020) used CNN with data augmentation for mosquito classification. Their dataset contains was 442 images. They used random forest, SVM, XGBoost, and CNN (VGG16). CNN outperforms the other classifiers in terms of accuracy where it gives the accuracy of 93%. After augmentation of images, the number of images was 36000. Junyony Park et al. (Park et al., 2020) worked on the morphological analysis of vector and classification of mosquitoes. They have collected 3600 images of eight different species of mosquitoes. They used CNN and achieved an accuracy of 96.6%. The summary of related work is present in Table 1 .",
            "cite_spans": [
                {
                    "start": 13,
                    "end": 33,
                    "text": "(Akter et al., 2020)",
                    "ref_id": "BIBREF0"
                },
                {
                    "start": 367,
                    "end": 386,
                    "text": "(Park et al., 2020)",
                    "ref_id": "BIBREF17"
                }
            ],
            "ref_spans": [
                {
                    "start": 633,
                    "end": 640,
                    "text": "Table 1",
                    "ref_id": null
                }
            ],
            "section": "Related work"
        },
        {
            "text": "The proposed system uses data pre-processing technologies to achieve maximum classification performance and explore the methods to classify the images using minimum computational complexity. These pre-processing techniques include data augmentation, Region of interest (ROI) based image slicing to focus on specific body parts of the mosquito image, forward features selection (FFS) to select the best features from RGB feature sets. The image classification has been done using different ML and Deep learning models to analyze each approach and model for its best performance and computational complexity. The proposed study uses Aedes and Culex dataset obtain from IEEE data port.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Related work"
        },
        {
            "text": "This study uses an open-access image dataset of Aedes and Culex mosquitoes species (Reshma Pise, 2020) obtained from the IEEE data port. The dataset contains images of two species of mosquitoes named Culex and Aedes. There are a total of 1404 images of the mosquitoes. Out of 1,404 images, there are 810 images of Aedes and 594 images of Culex class. In the Culex class, out of 594 images, 432 images have been used for training purposes, and 162 images are used for the testing. Similarly, out of 810 images of the Aedes class, 591 images have been used for the training, and 219 images used for the testing purpose. Thus, the total images for the training are 1023 and 381 images for testing as shown in Table 2 and the sample of the dataset is shown in Fig. 1 .",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 706,
                    "end": 713,
                    "text": "Table 2",
                    "ref_id": "TABREF2"
                },
                {
                    "start": 756,
                    "end": 762,
                    "text": "Fig. 1",
                    "ref_id": null
                }
            ],
            "section": "Dataset description"
        },
        {
            "text": "The data processing technique is used to increase the amount of data by adding slightly modified copies of already existing data or develops new synthetic data from the existing data. It works as a regularizer and assists to overcome over-fitting while training a model (Shorten and Khoshgoftaar, 2019) . Data augmentation techniques are closely related to the oversampling in data analysis. It increases the diversity of data that is available for training models without actually collecting new data. In this study, a sharp filter for data augmentation has been used to generate one more image from an original image. Data augmentation has only being applied on the training set. Training images count after augmentation shown in Table 3 and applied sharp kernel shown in Fig. 2 .",
            "cite_spans": [
                {
                    "start": 270,
                    "end": 302,
                    "text": "(Shorten and Khoshgoftaar, 2019)",
                    "ref_id": "BIBREF23"
                }
            ],
            "ref_spans": [
                {
                    "start": 732,
                    "end": 739,
                    "text": "Table 3",
                    "ref_id": "TABREF3"
                },
                {
                    "start": 774,
                    "end": 780,
                    "text": "Fig. 2",
                    "ref_id": null
                }
            ],
            "section": "Data augmentation"
        },
        {
            "text": "Sharpening an image is a feature enhancement methodology whose purpose is to highlight the fine details in an image. Typically, this technique uses linear filters for implementing the high pass filters, which may produce unlikely results. The reason being, the linear filters are incapable of sharpening correctly if the image is being corrupted with noise. Therefore, before image sharpening, image soothing and filtering need to be carried out, which involve low pass filters and replacement of pixels. Sharpening enhances the structure and the other details of an image. These line structures and edges of an image can be obtained through the application of a high pass filter over an image. The high pass filter is a spatial operation that takes the difference between the current and averaging weights of the nearby pixels by using matrices. The high pass filter is then used to design a sharpening filter that produces the desired, appropriately scaled, high-pass sharpened image, and the result after applying a sharp filter is shown in Fig. 3 .",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 1044,
                    "end": 1050,
                    "text": "Fig. 3",
                    "ref_id": "FIGREF0"
                }
            ],
            "section": "Data augmentation"
        },
        {
            "text": "VGG-16 is a renowned convolutional network. It was developed by the visual geometry group which is also known as VGG-16. Instead of having many hyper parameters, VGG16 only focuses on having convolutional layers of 3 \u00c2 3 filters with stride 1 and uses the same max pool and padding layer of 2 \u00c2 2 filters of stride 2. In the end, it has 2 fully connected layers followed by the softmax for the output. This 16 in VGG-16 represents the 16 layers that have weights. VGG-16 has approximately 138 million parameters so, it is a large network. VGG is a pre-trained version of the net- Table 1 Summary of the systematic analysis studies in related work.",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 580,
                    "end": 587,
                    "text": "Table 1",
                    "ref_id": null
                }
            ],
            "section": "VGG-16"
        },
        {
            "text": "Year Dataset Accuracy Classes (Minakshi et al., 2017) 2017 60 images 83.3% -Fuad et al. (Fuad et al., 2018) 2018 Self made 534 images 99% cross entropy Aedes larvae Fanioudakis et al. (Fanioudakis et al., 2018) 2018 N/A 96% Classification of the mosquitoes based on the wingbeats Huang et al. (Huang et al., 2018) 2018 Self-made 90.5% CNN Aedes and culex Ortiz et al. (Ortiz et al., 2018) 2018 work trained on more than a billion images from the ImageNet database (Simonyan and Zisserman). It can classify images into thousands of object categories, which results in the learning of networks on rich features representation for various images. The image input size in VGG-16 is 224 \u00c2 224 (Theckedath and Sedamkar, 2020).",
            "cite_spans": [
                {
                    "start": 30,
                    "end": 53,
                    "text": "(Minakshi et al., 2017)",
                    "ref_id": "BIBREF13"
                },
                {
                    "start": 88,
                    "end": 107,
                    "text": "(Fuad et al., 2018)",
                    "ref_id": "BIBREF4"
                },
                {
                    "start": 184,
                    "end": 210,
                    "text": "(Fanioudakis et al., 2018)",
                    "ref_id": "BIBREF3"
                },
                {
                    "start": 293,
                    "end": 313,
                    "text": "(Huang et al., 2018)",
                    "ref_id": "BIBREF11"
                },
                {
                    "start": 368,
                    "end": 388,
                    "text": "(Ortiz et al., 2018)",
                    "ref_id": "BIBREF16"
                }
            ],
            "ref_spans": [],
            "section": "Study"
        },
        {
            "text": "By modifying the previous inception architecture inception, V3 has a quality that it uses less computation power. Comparing other inception networks like GoogLeNet/ inception V1, inception V3 is more efficient in terms of memory and resources. In the inception V3 network, some techniques for optimizing the network have been put suggested to loosen the constraint for easier model adoption. Their techniques are factorized convolutions, dimension reduction, regularization, and parallelized competitions. Due to factorized convolution, inception V3 uses less number of parameters involved in the network. Bigger convolution replaced with smaller convolution might increase the training speed of the inception V3. In inception V3, auxiliary classifier acts as a regularizer, and grid size reduction is usually done by pooling operation.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Inception V3"
        },
        {
            "text": "ResNet-50 is a variant of a convolutional neural network that is 50 layers deep. It is frequently used as a starting point for transfer learning. The concept of skip connection was firstly introduced by residual network 50. The ResNet model consists of five stages where each with the convolutional and identity block. Every convolutional block comprises 3 convolutional layers. ResNet-50 has over 23 million trainable parameters. Skip connections are used to add the output from a previous layer to the next coming layer. This helps to mitigate the vanishing gradient problem. Resnet-50 is comparable to the VGG-16 accept that ResNet-50 has the capability of additional identity mapping (Theckedath and Sedamkar, 2020) as shown in Fig. 4 .",
            "cite_spans": [
                {
                    "start": 688,
                    "end": 719,
                    "text": "(Theckedath and Sedamkar, 2020)",
                    "ref_id": "BIBREF28"
                }
            ],
            "ref_spans": [
                {
                    "start": 732,
                    "end": 738,
                    "text": "Fig. 4",
                    "ref_id": "FIGREF1"
                }
            ],
            "section": "ResNet-50"
        },
        {
            "text": "ResNet-50 predicts The Delta which is necessary to reach the final prediction from one layer to another (He et al., 2016) .",
            "cite_spans": [
                {
                    "start": 104,
                    "end": 121,
                    "text": "(He et al., 2016)",
                    "ref_id": "BIBREF10"
                }
            ],
            "ref_spans": [],
            "section": "ResNet-50"
        },
        {
            "text": "EfficientNet is a group of convolutional neural networks. It is more effective than most of its contemporaries. EfficientNet model consists of eight models from the B0 model to the B7 model (Tan and Le, 2019) . With every subsequent model number referred to variants with more parameters and higher accuracy. Similar to any other model, EfficientNet saves time and computational power. In doing so, it gives better results than many known models. This is all because of intelligent scaling at depth, width, and resolution. EfficientNet enables the use of deep learning on mobile and other edge devices. There is a compound scaling method in EfficientNet that uses compound coefficient $\\phi$ to uniformly scale network width, depth, and resolution in a principle way: Where, the constants a, b, and c can be found by using small grid search. u represents a user-specified coefficient which determines the number of resources ready for model scaling. And To determine the assignment of extra resources to network width, depth, and resolution is represented by a, b, c respectively.",
            "cite_spans": [
                {
                    "start": 190,
                    "end": 208,
                    "text": "(Tan and Le, 2019)",
                    "ref_id": "BIBREF27"
                }
            ],
            "ref_spans": [],
            "section": "EfficientNetBo"
        },
        {
            "text": "3.4. Machine learning models 3.4.1. Extra tree classifier (ETC) ETC develops a group of unpruned decision trees following the top-down method. While splitting a node of a tree, involves randomizing both attribute and cut point selection strongly. In extreme conditions, it develops fully randomized trees with structures independent of the training sample's output value. The main difference between the other famous ML model random forest, ETC is: ETC uses the whole dataset for the training of a model, while random forest uses bootstrap replica for training. ETC randomly picks the best features along with the corresponding values to split the node.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "EfficientNetBo"
        },
        {
            "text": "Due to these qualities, an extra tree classifier is less likely to overfit a dataset and gives better performance (Geurts et al., 2006) .",
            "cite_spans": [
                {
                    "start": 114,
                    "end": 135,
                    "text": "(Geurts et al., 2006)",
                    "ref_id": "BIBREF8"
                }
            ],
            "ref_spans": [],
            "section": "EfficientNetBo"
        },
        {
            "text": "Extra tree classifier has pros for calculation of the essential features. For calculating the importance feature X m for predicting Y in a tree structure T by summing up the decrease in the weighted impurity (p t )D i(S t, t) for all nodes t, where feature X m is used, then averaging over all N t trees in the forest.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "EfficientNetBo"
        },
        {
            "text": "where p(t) is the proportion of N N T samples reaching node t and v(S t )",
            "cite_spans": [],
            "ref_spans": [],
            "section": "EfficientNetBo"
        },
        {
            "text": "is the feature used in split S t (Bhati and Rai, 2020) . The decrease in some impurity measures i(t) at node t is represented by the following formula:",
            "cite_spans": [
                {
                    "start": 33,
                    "end": 54,
                    "text": "(Bhati and Rai, 2020)",
                    "ref_id": "BIBREF1"
                }
            ],
            "ref_spans": [],
            "section": "EfficientNetBo"
        },
        {
            "text": "Where, p L = Nt/N, p R = NtR/N and split st = s* for which the partition of the N node samples into two subsets t L and t R uplift the decrease in the impurity is identified. The construction of trees stops if the nodes are pure in terms of Y. Gini index is used as an impurity function and this is known as Gini importance or means decrease Gini. Table 4 shows the hyper-parameters for the used machine learning models. The models tuning has been performed to get this parameters setting.",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 348,
                    "end": 355,
                    "text": "Table 4",
                    "ref_id": null
                }
            ],
            "section": "EfficientNetBo"
        },
        {
            "text": "Training a model on a high-dimensional dataset is generally very challenging. Many ML models can easily over-fit and usually need wary hyper-parameter tuning when trained on a highdimensional dataset. The feature reduction techniques help reduce the dimensions of a given dataset (Singh et al., 2009) . The feature reduction process has to be performed very carefully to eliminate the redundant or irrelevant features from the data set. This elimination is done based on their predictive power, rather than eliminating features randomly. The feature reduction presents the following advantages:",
            "cite_spans": [
                {
                    "start": 280,
                    "end": 300,
                    "text": "(Singh et al., 2009)",
                    "ref_id": "BIBREF25"
                }
            ],
            "ref_spans": [],
            "section": "Feature selection"
        },
        {
            "text": "Training time is decreased due to decreased number of features. Fewer chances of overfitting due to reduced dimensionality. Increases interpret-ability in models and makes them simple. Decreases the effect of the curse of dimensionality.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Feature selection"
        },
        {
            "text": "Feature selection is the process of finding the most appropriate features of a given dataset . It is beneficial for the improvement of classification accuracy as well as computational speed. In most of the classification problem domains, the number of features is in hundreds and thousands, so selecting useful features out of such a large number of features is a challenging task. In this study, a hybrid feature selection method named RIFS has been introduced, which combines two feature selection methods -the ROI-based image filtering and the wrappers-based FFS technique. The refined images with selected ROI have been first obtained from the primary feature set using image filters. These features have further been refined by applying wrapper feature selection methods like FFS. This hybrid mechanism takes advantage of both the image filters and the wrappers. The mechanism has been examined by using different ML and CNN models. The results prove that a smaller refined feature set produces better classification accuracy with decreased computational complexity than feature sets with a large number of features.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Feature selection"
        },
        {
            "text": "{ROI} ROI extraction deals with the extraction of the intended shape signatures by applying edge detection techniques. Edge detection is a digital image processing technique in which an image is segmented into different regions with discontinuities. Edge detection techniques are most commonly used in image morphology, pattern recognition, and feature extraction. In feature extraction edge detection-based ROI extraction technique enables us to select an intended region of the total image. It minimizes the computational complexity by reducing data processing to recognize the required features for any classification task. Thus, the edge detection technique has been applied to the whole images to crop the needed region of the images necessary in mosquito classification.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Feature selection"
        },
        {
            "text": "FFS is a technique that notably reduces the number of models that need to be learned (Whitney, 1971) . The technique starts with a null model, and the features are added one at a time, choose the best model among the bests in each iteration. That is, the next feature is selected, and its metric value is calculated. The feature which gives the best metric value is added to the feature list. The process is repeated for two features, one from the selected feature set and one selected from the set of all remaining features. Again the metric value is evaluated, and compared to every featured pair, the feature with the best metric value is added to the selected feature set. The process is reiterated till a desired n number of features are obtained. This feature set of n features can be referred to as hyper-parameter FFS is thus a feasible technique to tune the hyper-parameter to obtain the optimal performance. Table 4 Hyper-parameters of machine learning algorithms used in our study.",
            "cite_spans": [
                {
                    "start": 85,
                    "end": 100,
                    "text": "(Whitney, 1971)",
                    "ref_id": "BIBREF32"
                }
            ],
            "ref_spans": [
                {
                    "start": 918,
                    "end": 925,
                    "text": "Table 4",
                    "ref_id": null
                }
            ],
            "section": "FFS"
        },
        {
            "text": "Hyper-parameters The linear model has been mainly used with FFS to find the features subset. To reduce the time complexity because it takes less time to train than non-linear models. Consider that if there are r rows in a dataset, the time taken to run the above algorithm will be:",
            "cite_spans": [],
            "ref_spans": [],
            "section": "ML Algorithms"
        },
        {
            "text": "which can be simplify as:",
            "cite_spans": [],
            "ref_spans": [],
            "section": "ML Algorithms"
        },
        {
            "text": "The proposed RIFS technique shown in Fig. 5 and can be defined mathematically as follows:",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 37,
                    "end": 43,
                    "text": "Fig. 5",
                    "ref_id": null
                }
            ],
            "section": "ML Algorithms"
        },
        {
            "text": "The proposed RIFS technique shown in Fig. 5 can be defined mathematically as follows:",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 37,
                    "end": 43,
                    "text": "Fig. 5",
                    "ref_id": null
                }
            ],
            "section": "ML Algorithms"
        },
        {
            "text": "The matrix in equation (9) shows the image features and equation (10) shows the RoIs from image. ",
            "cite_spans": [],
            "ref_spans": [],
            "section": "ML Algorithms"
        },
        {
            "text": "This study performs all experiments on the Core i7 7th generation machine with Windows 10 operating system with 8 GB RAM and 500 GB HDD. Jupyter notebook has been used for the implementation of python code.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Proposed methodology workflow"
        },
        {
            "text": "The proposed methodology uses different techniques and methods to classify the Aedes and Culex. As a first step in the workflow, the dataset has been obtained from an IEEE data port. The obtained dataset has then been preprocessed to improve learning models' performance and compensate for computational complexity. Thus, in preprocessing step, data augmentation and RIFS feature selection have been performed. The data augmentation technique is used to increase the number of images for models' learning because the original dataset is not large enough, so the numbers of features are not enough for a good fit. For data augmentation, a sharp filter method has been used, generating one more image corresponding to each image from the training set. The data augmentation technique has been applied only on the training set to double the training set's size, as shown in Table 5 and training, testing images count shown in Table 6 .",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 871,
                    "end": 878,
                    "text": "Table 5",
                    "ref_id": "TABREF6"
                },
                {
                    "start": 923,
                    "end": 930,
                    "text": "Table 6",
                    "ref_id": null
                }
            ],
            "section": "Proposed methodology workflow"
        },
        {
            "text": "After data augmentation, the RIFS has been applied to extract the specific parts of mosquito bodies such as the abdomen, legs, head, and thorax because these parts are important for visual recognition of both mosquito types. The effect of the ROI step of RIFS of the images is shown in Fig. 6 .",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 286,
                    "end": 292,
                    "text": "Fig. 6",
                    "ref_id": null
                }
            ],
            "section": "Proposed methodology workflow"
        },
        {
            "text": "The ROI phase of RIFS generates more specific features to learn as compared to learn whole images. After the ROI extraction, the RGB features have been extracted from selected images, and these RGB features have been passed to forward features selection (FFS). Through FFS, the important features are selected for the learning of models to improve the performance. Since all the features are not correlated to the target class, only the important features are selected. The models have been trained using the resulted training set, and then the performance evaluation of the models has been performed using the test data. The important metrics, including accuracy, precision, recall, F1-score, and ROC AUC, have been calculated to evaluate learning models. Proposed methodology diagram shown in Fig. 7 ",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 795,
                    "end": 801,
                    "text": "Fig. 7",
                    "ref_id": "FIGREF5"
                }
            ],
            "section": "Proposed methodology workflow"
        },
        {
            "text": "This study deals with the classification of mosquito images for that different deep learning and ML models have been used. The comparative analysis of model performances and computational complexity of different approaches has been evaluated. This section presents the results of all models individually on the given datasets in different scenarios.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Results"
        },
        {
            "text": "The performance evaluation results of all the used models on the original dataset without any preprocessing have been presented in this section. The models in this scenario have been trained on the RGB features of the original images of the primary dataset, and the performance metrics of ML models such as accuracy, precision, recall, and F1 score has been presented in Table 7 .",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 371,
                    "end": 378,
                    "text": "Table 7",
                    "ref_id": "TABREF7"
                }
            ],
            "section": "Model performances on primary dataset"
        },
        {
            "text": "The confusion matrix obtained from the current model scenario has been shown in Table 8 .",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 80,
                    "end": 87,
                    "text": "Table 8",
                    "ref_id": null
                }
            ],
            "section": "Model performances on primary dataset"
        },
        {
            "text": "The performance of the CNN variants has also been evaluated for the same on the same original dataset images and has been reported in Table 9 . As shown in the results VVG16 in this case outperforms all the other CNN Variants and the ML models whose results are presented in the previous subsection. Thus VVG16 gives 0.955 accuracy score which shows the significance of the deep learning approach in the current application domain.",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 134,
                    "end": 141,
                    "text": "Table 9",
                    "ref_id": null
                }
            ],
            "section": "Model performances on primary dataset"
        },
        {
            "text": "In this scenario the models have been trained on ROI processed dataset. The highest performance in this setup has been given by ETC followed by RF. As shown in the results the ETC provided accuracy score of 0.98 and RF performs closely with the accuracy score of 0.979. As shown in Table 11 , the performances of all models improve when trained on this refined version of the dataset. As shown in Table 12 , ETC gives the highest number of correct predictions, i.e 376 out of 381 and lowest false predictions as compared to other ML models.",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 282,
                    "end": 290,
                    "text": "Table 11",
                    "ref_id": "TABREF9"
                },
                {
                    "start": 397,
                    "end": 405,
                    "text": "Table 12",
                    "ref_id": "TABREF2"
                }
            ],
            "section": "Model performance after ROI extraction of images"
        },
        {
            "text": "The CNN variants' performance is shown in Table 13 , and results show that the performance of the CNN variants also improves after ROI extraction of images. The performance of VVG16 increased from 0.955 to 0.986, which shows the significance of ROI-based region specific feature learning for both machine learning and deep learning models. As discussed earlier, the specific region of images gives the specific features for learning which is significant to improve model performances.",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 42,
                    "end": 50,
                    "text": "Table 13",
                    "ref_id": "TABREF3"
                }
            ],
            "section": "Model performance after ROI extraction of images"
        },
        {
            "text": "This section presents results after the application of the RIFS technique to select the important features from images. RIFS is a combination of ROI and FFS techniques that help to boost ML models' performance and gives the highest results of this study. RIFS return important features which are significantly correlated features to learn as compared to original dataset image features. All ML models improve their performance with RIFS, as shown in Table 15 . ETC gives the highest accuracy score of 0.992, which shows the significance of the proposed feature extraction approach, while the other models as RF and LR, and also improve their performance with an accuracy score of 0.984 and 0.976, respectively. Table 16 shows the confusion matrix for all ML models, and results show that ETC gives 378 correct predictions out of 381, which is the highest correct prediction ratio of the study.",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 450,
                    "end": 458,
                    "text": "Table 15",
                    "ref_id": "TABREF6"
                },
                {
                    "start": 711,
                    "end": 719,
                    "text": "Table 16",
                    "ref_id": null
                }
            ],
            "section": "Model performance on application of proposed RIFS technique"
        },
        {
            "text": "The CNN variants' performance also improves with RIFS, which shows the significance of the RIFS approach for mosquito image classification using both types of classification models. The results of the CNN variants are shown in Table 17 , and according to the results, InceptionV3, ResNet-50, and EfficientNetB0 improve their results compared to previous results, while VGG16 results remain the same as on ROI based feature extraction. According to the confusion matrix in Table 18 , the VGG16 is on top with 376 correct classifications and only five wrong classifications. CNNs' accuracy and loss graph shown in Fig. 8 .",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 227,
                    "end": 235,
                    "text": "Table 17",
                    "ref_id": "TABREF7"
                },
                {
                    "start": 472,
                    "end": 480,
                    "text": "Table 18",
                    "ref_id": null
                },
                {
                    "start": 612,
                    "end": 618,
                    "text": "Fig. 8",
                    "ref_id": "FIGREF6"
                }
            ],
            "section": "Model performance on application of proposed RIFS technique"
        },
        {
            "text": "To check the significance of this study, a comparative analysis with prior studies on mosquito image classification has also been performed. The proposed models used in these studies have been applied to the dataset used in this study. The results show that the proposed approach has more significant results than prior studies. The comparison of results with state-of-the-art models Table 6 Training and testing images count.",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 384,
                    "end": 391,
                    "text": "Table 6",
                    "ref_id": null
                }
            ],
            "section": "Comparison with other studies"
        },
        {
            "text": "Training Testing   Culex  854  162  Aedes  1182  219  Total  2046 Table 8 Confusion matrix for all machine learning models on the original dataset. TP  TN  FP  FN  CP  WP   SVM  162  67  57  95  229  152  RF  181  87  38  75  268  113  ETC  182  90  37  72  272  109  LR  173  66  46  96  239  142  KNN  177  92  42  70  269  112   Table 9 Performance of CNN variant on the original dataset. ",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 9,
                    "end": 65,
                    "text": "Testing   Culex  854  162  Aedes  1182  219  Total  2046",
                    "ref_id": "TABREF2"
                },
                {
                    "start": 66,
                    "end": 73,
                    "text": "Table 8",
                    "ref_id": null
                },
                {
                    "start": 148,
                    "end": 339,
                    "text": "TP  TN  FP  FN  CP  WP   SVM  162  67  57  95  229  152  RF  181  87  38  75  268  113  ETC  182  90  37  72  272  109  LR  173  66  46  96  239  142  KNN  177  92  42  70  269  112   Table 9",
                    "ref_id": "TABREF2"
                }
            ],
            "section": "Type"
        },
        {
            "text": "To prove the computational complexity improvement given by ETC, the selected best performing ML model. The comparative analysis has been performed between ETC and the CNN models. The results reveal that ETC takes 46 times less training time as compared to fastest trained CNN model, InceptionV3. Thus the results presented in Table 21 show the computational requirements of ETC in terms of time is significantly low in terms of accuracy as compared to CNN variants and other ML models. These results prove that machine learning models can also perform very well as neural network models on image dataset in terms of both accuracy and computational time.",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 326,
                    "end": 334,
                    "text": "Table 21",
                    "ref_id": "TABREF2"
                }
            ],
            "section": "Time complexity comparison between proposed approach model ETC and other CNN variants"
        },
        {
            "text": "This study deals with the development of methodology for the classification of disease spreading mosquitoes. Various state-ofthe-art ML, CNN models and studies have been investigated, analyzed and applied to propose an effective method in terms of accuracy and computational time.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Discussion"
        },
        {
            "text": "As shown in the results, the ensemble model ETC outperforms all other ML models with a 0.713 accuracy score. RF and KNN have also performed comparatively well with accuracy scores of 0.703 and 0.706 respectively. However SVM and LR couldn't perform well, because in the current scenario these models required an extensive feature set for learning, compared to RF, ETC, and KNN. The highest correct predictions in this scenario are given by the ETC, which is 272 out of 381, as shown in confusion matrix of Table 8 . In addition, all CNN variants give higher performance results as compared to all the ML models. These pre-trained models used the neural networks in their architecture which are more appropriate to extract important features for learning and help to boost their accuracy. ML models have no such mechanisms to find important features for learning automatically. That is the reason ML models are not performing well as compared to CNN models. Results reveal that the VVG16 gives 364 correct predictions out of 381 and only 17 wrong predictions, as shown in Table 10 , which is the lowest wrong prediction ratio as compared to all other models on the original image dataset.",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 506,
                    "end": 513,
                    "text": "Table 8",
                    "ref_id": null
                },
                {
                    "start": 1071,
                    "end": 1079,
                    "text": "Table 10",
                    "ref_id": null
                }
            ],
            "section": "ML and CNN models without data preprocessing"
        },
        {
            "text": "The image dataset has been preprocessed to extract the specific regions of images using ROI extraction. Thus after getting the images consisting of only the specific parts which are relevant in mosquito image classification in a refined version of the dataset. All the ML models have been then trained using the dataset containing the images with specific regions of interest. On testing the models after application of ROI based feature extraction, athe model performances were significantly improved. Since the model learning in this scenario was based on more relevant features needed for image classification. While as all the other irrelevant image regions were cropped out to eliminate the features not required for the classification. VVG16 is equal in performance with machine learning model ETC because the ROI based machine learning model gets same important features. ML models provided a high score as compared to InceptionV3, ResNet-50, and EfficientNetB0 because these models perform better given a large feature set while after selected feature set size to reduce which is not suitable for CNN variant but machine learning models. VVG16 gives 376 correct predictions out of 381, equal in number with ETC shown in Table 14 .",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 1228,
                    "end": 1236,
                    "text": "Table 14",
                    "ref_id": null
                }
            ],
            "section": "ML and CNN models with ROI based data preprocessing"
        },
        {
            "text": "The ETC model performs well in this scenario because of its ensemble architecture. It combines several decision trees in the classification procedure using majority voting criteria which makes it a more suitable model compared to individual classification models.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "ML and CNN models with RIFS data preprocessing"
        },
        {
            "text": "The comparison between all model performances shows that ROI and RIFS based feature extraction techniques improve model performances very significantly as compared to training on features of the original dataset. This is because these techniques help extract very specific and more meaningful features for learning, which helps boost models' performance. Fig. 9 shows that ML models are not performing well on the original dataset. However, the CNNs' performance is better on original dataset images because these models automatically learn on good features. ML models' performance boosts right after the ROI extraction of specific parts of mosquito's from images. This technique enables the models to use the most appropriate features for classification and improves the results while the RIFS technique helps more to improve model performances.",
            "cite_spans": [],
            "ref_spans": [
                {
                    "start": 355,
                    "end": 361,
                    "text": "Fig. 9",
                    "ref_id": "FIGREF7"
                }
            ],
            "section": "ML and CNN models with RIFS data preprocessing"
        },
        {
            "text": "Why this study is significant?",
            "cite_spans": [],
            "ref_spans": [],
            "section": "ML and CNN models with RIFS data preprocessing"
        },
        {
            "text": "The study experiments are based on a dataset which has never been used previously in any of the studies according to best of our knowledge. This study proposes a novekl approach in which the ML model outperforms the strong CNN Variant. This study introduces the RIFS approach which shows that the focus on the important features can improve ML model performance and also can save computation time and cost. The study performs a strong comparison between well-tuned baseline models to show the significance of the proposed approach",
            "cite_spans": [],
            "ref_spans": [],
            "section": "ML and CNN models with RIFS data preprocessing"
        },
        {
            "text": "Many Mosquito-borne diseases are deadly as the antiviral and antibiotic drugs are not effective in treating the infected patients. This becomes a primary reason for almost one million human deaths per year in the world. The current best-known approach to prevent the spread of mosquito-borne diseases is to eliminate the possible presence of mosquitoes and their breeding areas using different chemical and insecticide sprays. However, the complete elimination of these flying insects becomes challenging because these sprays or chemical applications' abundant use creates resistance in the mosquitoes.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Conclusion"
        },
        {
            "text": "Identifying disease-transmitting mosquitoes in any potential area demands an efficient automatic system to detect and classify the particular types of mosquitoes. The system will aid the health authorities and other stack holders to check the presence of any disease-spreading mosquito in the area of their interest. In this study, an ML and CNN-based methodology has been proposed to develop an effective system that will effectively aid in epidemiology to design evidence-based policies and decisions by analyzing the risks and transmission. It will prepare the authorities to take preventive measures in the targeted areas to control its spread at the right time. This study proposes a methodology for classifying the most important classes of disease-spreading mosquitoes such as Aedes and Culex using ML and CNN-based approaches. The study uses a primary image dataset of Aedes and Culex mosquitoes species obtained from the IEEE data port, a well-known source for the datasets. The dataset contains the images of two species of mosquitoes named Culex and Aedes. A novel feature selection approach, RIFS, has been proposed and evaluated in this study. The objective was to benefit from image filtering techniques' efficiency and the accuracy of wrapper-based feature selection techniques. So the RIFS was designed as a hybrid feature selection preprocessing technique. The first phase of the feature selection eliminates the irrelevant portions of images to increase efficiency and reduce the computational cost. In the second phase, the most appropriate features are being selected to improve the model accuracies. In the experimental setup, all the applied ML models such as SVM, RF, ETC, LR, and KNN and CNN model variants such as VG16, InceptionV3, ResNet 50, and EfficientNetB0 have been trained to evaluate the performance and computational cost of each model.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Conclusion"
        },
        {
            "text": "The results show that the proposed methodology based on the novel feature selection approach RIFS is very effective on both model efficiencies and computational complexity. It is also believed that the methodology can also apply to other different problem areas involving effective feature selection. The main findings in the results show that the ETC outperformed among all the ML models giving 0.992 accuracy, which was performing as low as 0.71 before the application of RIFS. VVG16 attained 0.986 accuracy when the proposed RIFS was applied. These observations prove that the low-performing ML models can also achieve a significant performance while also reducing the computational efforts when using appropriate feature selection. As can be seen in the results, the ETC model takes very less training time and testing time compared to all other models.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Conclusion"
        },
        {
            "text": "The authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper. ",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Declaration of Competing Interest"
        }
    ],
    "bib_entries": {
        "BIBREF0": {
            "ref_id": "b0",
            "title": "Mosquito classication using convolutional neural network with data augmentation",
            "authors": [
                {
                    "first": "M",
                    "middle": [],
                    "last": "Akter",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [
                        "S"
                    ],
                    "last": "Hossain",
                    "suffix": ""
                },
                {
                    "first": "T",
                    "middle": [],
                    "last": "Ahmed",
                    "suffix": ""
                },
                {
                    "first": "K",
                    "middle": [],
                    "last": "Andersson",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "3rd International Conference on Intelligent Computing & Optimization 2020",
            "volume": "2020",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF1": {
            "ref_id": "b1",
            "title": "Ensemble based approach for intrusion detection using extra tree classifier",
            "authors": [
                {
                    "first": "B",
                    "middle": [
                        "S"
                    ],
                    "last": "Bhati",
                    "suffix": ""
                },
                {
                    "first": "C",
                    "middle": [],
                    "last": "Rai",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "Intelligent Computing in Engineering",
            "volume": "",
            "issn": "",
            "pages": "213--220",
            "other_ids": {}
        },
        "BIBREF2": {
            "ref_id": "b2",
            "title": "Japanese encephalitis information from Taiwan cdc",
            "authors": [
                {
                    "first": "D",
                    "middle": [],
                    "last": "Center Taiwan",
                    "suffix": ""
                }
            ],
            "year": 2021,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF3": {
            "ref_id": "b3",
            "title": "Mosquito wingbeat analysis and classification using deep learning",
            "authors": [
                {
                    "first": "E",
                    "middle": [],
                    "last": "Fanioudakis",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Geismar",
                    "suffix": ""
                },
                {
                    "first": "I",
                    "middle": [],
                    "last": "Potamitis",
                    "suffix": ""
                }
            ],
            "year": 2018,
            "venue": "26th European SignalProcessing Conference (EUSIPCO) IEEE",
            "volume": "",
            "issn": "",
            "pages": "2410--2414",
            "other_ids": {}
        },
        "BIBREF4": {
            "ref_id": "b4",
            "title": "Training of convolutional neural networkusing transfer learning for aedes aegypti larvae",
            "authors": [
                {
                    "first": "M",
                    "middle": [
                        "A M"
                    ],
                    "last": "Fuad",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [
                        "R"
                    ],
                    "last": "Ghani",
                    "suffix": ""
                },
                {
                    "first": "R",
                    "middle": [],
                    "last": "Ghazali",
                    "suffix": ""
                },
                {
                    "first": "T",
                    "middle": [
                        "A"
                    ],
                    "last": "Izzuddin",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [
                        "F"
                    ],
                    "last": "Sulaima",
                    "suffix": ""
                },
                {
                    "first": "Z",
                    "middle": [],
                    "last": "Jano",
                    "suffix": ""
                },
                {
                    "first": "T",
                    "middle": [],
                    "last": "Sutikno",
                    "suffix": ""
                }
            ],
            "year": 2018,
            "venue": "Telkomnika",
            "volume": "16",
            "issn": "4",
            "pages": "1894--1900",
            "other_ids": {}
        },
        "BIBREF5": {
            "ref_id": "b5",
            "title": "Visionbased perception and classification of mosquitoes using supportvector machine",
            "authors": [
                {
                    "first": "M",
                    "middle": [],
                    "last": "Fuchida",
                    "suffix": ""
                },
                {
                    "first": "T",
                    "middle": [],
                    "last": "Pathmakumar",
                    "suffix": ""
                },
                {
                    "first": "R",
                    "middle": [
                        "E"
                    ],
                    "last": "Mohan",
                    "suffix": ""
                },
                {
                    "first": "N",
                    "middle": [],
                    "last": "Tan",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Nakamura",
                    "suffix": ""
                }
            ],
            "year": 2017,
            "venue": "Appl. Sci",
            "volume": "7",
            "issn": "1",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF6": {
            "ref_id": "b6",
            "title": "Co-distribution and coinfection of chikungunya and dengue viruses",
            "authors": [
                {
                    "first": "L",
                    "middle": [],
                    "last": "Furuya-Kanamori",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Liang",
                    "suffix": ""
                },
                {
                    "first": "G",
                    "middle": [],
                    "last": "Milinovich",
                    "suffix": ""
                },
                {
                    "first": "R",
                    "middle": [
                        "J S"
                    ],
                    "last": "Magalhaes",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [
                        "C"
                    ],
                    "last": "Clements",
                    "suffix": ""
                },
                {
                    "first": "W",
                    "middle": [],
                    "last": "Hu",
                    "suffix": ""
                },
                {
                    "first": "P",
                    "middle": [],
                    "last": "Brasil",
                    "suffix": ""
                },
                {
                    "first": "F",
                    "middle": [
                        "D"
                    ],
                    "last": "Frentiu",
                    "suffix": ""
                },
                {
                    "first": "R",
                    "middle": [],
                    "last": "Dunning",
                    "suffix": ""
                },
                {
                    "first": "L",
                    "middle": [],
                    "last": "Yakob",
                    "suffix": ""
                }
            ],
            "year": 2016,
            "venue": "BMC Infect. Dis",
            "volume": "16",
            "issn": "1",
            "pages": "1--11",
            "other_ids": {}
        },
        "BIBREF7": {
            "ref_id": "b7",
            "title": "Mosquito Larvae Image Classification Based on DenseNet and Guided Grad-CAM",
            "authors": [
                {
                    "first": "Z",
                    "middle": [],
                    "last": "Garc\u00eda",
                    "suffix": ""
                },
                {
                    "first": "K",
                    "middle": [],
                    "last": "Yanai",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Nakano",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Arista",
                    "suffix": ""
                },
                {
                    "first": "L",
                    "middle": [],
                    "last": "Cleofas",
                    "suffix": ""
                },
                {
                    "first": "H",
                    "middle": [],
                    "last": "Perez-Meana",
                    "suffix": ""
                }
            ],
            "year": 2019,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {
                "DOI": [
                    "10.1007/978-3-030-31321-0_21"
                ]
            }
        },
        "BIBREF8": {
            "ref_id": "b8",
            "title": "Extremely randomized trees",
            "authors": [
                {
                    "first": "P",
                    "middle": [],
                    "last": "Geurts",
                    "suffix": ""
                },
                {
                    "first": "D",
                    "middle": [],
                    "last": "Ernst",
                    "suffix": ""
                },
                {
                    "first": "L",
                    "middle": [],
                    "last": "Wehenkel",
                    "suffix": ""
                }
            ],
            "year": 2006,
            "venue": "Machine Learning",
            "volume": "63",
            "issn": "1",
            "pages": "3--42",
            "other_ids": {}
        },
        "BIBREF9": {
            "ref_id": "b9",
            "title": "Efficacy and long-term safety of a dengue vaccine in regions of endemic disease",
            "authors": [
                {
                    "first": "S",
                    "middle": [
                        "R"
                    ],
                    "last": "Hadinegoro",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [
                        "L"
                    ],
                    "last": "Arredondo-Garc\u00eda",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [
                        "R"
                    ],
                    "last": "Capeding",
                    "suffix": ""
                },
                {
                    "first": "C",
                    "middle": [],
                    "last": "Deseda",
                    "suffix": ""
                },
                {
                    "first": "T",
                    "middle": [],
                    "last": "Chotpitayasunondh",
                    "suffix": ""
                },
                {
                    "first": "R",
                    "middle": [],
                    "last": "Dietze",
                    "suffix": ""
                },
                {
                    "first": "H",
                    "middle": [
                        "I"
                    ],
                    "last": "Hj Muhammad Ismail",
                    "suffix": ""
                },
                {
                    "first": "H",
                    "middle": [],
                    "last": "Reynales",
                    "suffix": ""
                },
                {
                    "first": "K",
                    "middle": [],
                    "last": "Limkittikul",
                    "suffix": ""
                },
                {
                    "first": "D",
                    "middle": [
                        "M"
                    ],
                    "last": "Rivera-Medina",
                    "suffix": ""
                },
                {
                    "first": "H",
                    "middle": [
                        "N"
                    ],
                    "last": "Tran",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Bouckenooghe",
                    "suffix": ""
                },
                {
                    "first": "D",
                    "middle": [],
                    "last": "Chansinghakul",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Cort\u00e9s",
                    "suffix": ""
                },
                {
                    "first": "K",
                    "middle": [],
                    "last": "Fanouillere",
                    "suffix": ""
                },
                {
                    "first": "R",
                    "middle": [],
                    "last": "Forrat",
                    "suffix": ""
                },
                {
                    "first": "C",
                    "middle": [],
                    "last": "Frago",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Gailhardou",
                    "suffix": ""
                },
                {
                    "first": "N",
                    "middle": [],
                    "last": "Jackson",
                    "suffix": ""
                },
                {
                    "first": "F",
                    "middle": [],
                    "last": "Noriega",
                    "suffix": ""
                },
                {
                    "first": "E",
                    "middle": [],
                    "last": "Plennevaux",
                    "suffix": ""
                },
                {
                    "first": "T",
                    "middle": [
                        "A"
                    ],
                    "last": "Wartel",
                    "suffix": ""
                },
                {
                    "first": "B",
                    "middle": [],
                    "last": "Zambrano",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Saville",
                    "suffix": ""
                }
            ],
            "year": 2015,
            "venue": "New England J. Med",
            "volume": "373",
            "issn": "13",
            "pages": "1195--1206",
            "other_ids": {}
        },
        "BIBREF10": {
            "ref_id": "b10",
            "title": "Deep residual learning for image recognition",
            "authors": [
                {
                    "first": "K",
                    "middle": [],
                    "last": "He",
                    "suffix": ""
                },
                {
                    "first": "X",
                    "middle": [],
                    "last": "Zhang",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Ren",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Sun",
                    "suffix": ""
                }
            ],
            "year": 2016,
            "venue": "Proceedings of the IEEE conference on computer vision andpattern recognition",
            "volume": "",
            "issn": "",
            "pages": "770--778",
            "other_ids": {}
        },
        "BIBREF11": {
            "ref_id": "b11",
            "title": "A vector mosquitoes classification system based on edge computing and deeplearning",
            "authors": [
                {
                    "first": "L.-P",
                    "middle": [],
                    "last": "Huang",
                    "suffix": ""
                },
                {
                    "first": "M.-H",
                    "middle": [],
                    "last": "Hong",
                    "suffix": ""
                },
                {
                    "first": "C.-H",
                    "middle": [],
                    "last": "Luo",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Mahajan",
                    "suffix": ""
                },
                {
                    "first": "L.-J",
                    "middle": [],
                    "last": "Chen",
                    "suffix": ""
                }
            ],
            "year": 2018,
            "venue": "2018 Conference on Technologies and Applications of Artificial Intelligence (TAAI)",
            "volume": "",
            "issn": "",
            "pages": "24--27",
            "other_ids": {}
        },
        "BIBREF12": {
            "ref_id": "b12",
            "title": "Stable transformation of the yellowfever mosquito, aedes aegypti, with the hermes element from the housefly",
            "authors": [
                {
                    "first": "N",
                    "middle": [],
                    "last": "Jasinskiene",
                    "suffix": ""
                },
                {
                    "first": "C",
                    "middle": [
                        "J"
                    ],
                    "last": "Coates",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [
                        "Q"
                    ],
                    "last": "Benedict",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [
                        "J"
                    ],
                    "last": "Cornel",
                    "suffix": ""
                },
                {
                    "first": "C",
                    "middle": [
                        "S"
                    ],
                    "last": "Rafferty",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [
                        "A"
                    ],
                    "last": "James",
                    "suffix": ""
                },
                {
                    "first": "F",
                    "middle": [
                        "H"
                    ],
                    "last": "Collins",
                    "suffix": ""
                }
            ],
            "year": 1998,
            "venue": "Proc. Natl. Acad. Sci",
            "volume": "95",
            "issn": "7",
            "pages": "3743--3747",
            "other_ids": {}
        },
        "BIBREF13": {
            "ref_id": "b13",
            "title": "Identifying mosquito species using smart-phone cameras",
            "authors": [
                {
                    "first": "M",
                    "middle": [],
                    "last": "Minakshi",
                    "suffix": ""
                },
                {
                    "first": "P",
                    "middle": [],
                    "last": "Bharti",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Chellappan",
                    "suffix": ""
                }
            ],
            "year": 2017,
            "venue": "2017 European Conference on Networksand Communications (EuCNC)",
            "volume": "",
            "issn": "",
            "pages": "1--6",
            "other_ids": {}
        },
        "BIBREF14": {
            "ref_id": "b14",
            "title": "Application of convolutional neural networks for classification of adult mosquitoes in the field",
            "authors": [
                {
                    "first": "D",
                    "middle": [],
                    "last": "Motta",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [
                        "\u00c1 B"
                    ],
                    "last": "Santos",
                    "suffix": ""
                },
                {
                    "first": "I",
                    "middle": [],
                    "last": "Winkler",
                    "suffix": ""
                },
                {
                    "first": "B",
                    "middle": [
                        "A S"
                    ],
                    "last": "Machado",
                    "suffix": ""
                },
                {
                    "first": "D",
                    "middle": [
                        "A D I"
                    ],
                    "last": "Pereira",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [
                        "M"
                    ],
                    "last": "Cavalcanti",
                    "suffix": ""
                },
                {
                    "first": "E",
                    "middle": [
                        "O L"
                    ],
                    "last": "Fonseca",
                    "suffix": ""
                },
                {
                    "first": "F",
                    "middle": [],
                    "last": "Kirchner",
                    "suffix": ""
                },
                {
                    "first": "R",
                    "middle": [],
                    "last": "Badaro",
                    "suffix": ""
                }
            ],
            "year": 2019,
            "venue": "PLoS ONE",
            "volume": "14",
            "issn": "1",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF15": {
            "ref_id": "b15",
            "title": "Vision-based classification of mosquito species: Comparison of conventional and deeplearning methods",
            "authors": [
                {
                    "first": "K",
                    "middle": [],
                    "last": "Okayasu",
                    "suffix": ""
                },
                {
                    "first": "K",
                    "middle": [],
                    "last": "Yoshida",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Fuchida",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Nakamura",
                    "suffix": ""
                }
            ],
            "year": 2019,
            "venue": "Appl. Sci",
            "volume": "9",
            "issn": "18",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF16": {
            "ref_id": "b16",
            "title": "Mosquito larva classification based on a convolution neural network",
            "authors": [
                {
                    "first": "A",
                    "middle": [
                        "S"
                    ],
                    "last": "Ortiz",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [
                        "N"
                    ],
                    "last": "Miyatake",
                    "suffix": ""
                },
                {
                    "first": "H",
                    "middle": [],
                    "last": "T\u00fcnnermann",
                    "suffix": ""
                },
                {
                    "first": "T",
                    "middle": [],
                    "last": "Teramoto",
                    "suffix": ""
                },
                {
                    "first": "H",
                    "middle": [],
                    "last": "Shouno",
                    "suffix": ""
                }
            ],
            "year": 2018,
            "venue": "Proceedings of the International Conference on Parallel and Distributed Processing Techniques and Applications (PDPTA)",
            "volume": "",
            "issn": "",
            "pages": "320--325",
            "other_ids": {}
        },
        "BIBREF17": {
            "ref_id": "b17",
            "title": "Classification and morphological analysis of vector mosquitoes using deep convolutionalneural networks",
            "authors": [
                {
                    "first": "J",
                    "middle": [],
                    "last": "Park",
                    "suffix": ""
                },
                {
                    "first": "D",
                    "middle": [
                        "I"
                    ],
                    "last": "Kim",
                    "suffix": ""
                },
                {
                    "first": "B",
                    "middle": [],
                    "last": "Choi",
                    "suffix": ""
                },
                {
                    "first": "W",
                    "middle": [],
                    "last": "Kang",
                    "suffix": ""
                },
                {
                    "first": "H",
                    "middle": [
                        "W"
                    ],
                    "last": "Kwon",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "Sci. Rep",
            "volume": "10",
            "issn": "1",
            "pages": "1--12",
            "other_ids": {}
        },
        "BIBREF18": {
            "ref_id": "b18",
            "title": "Mayawadee Aungmaneeporn, Image dataset of aedes and culex mosquito species",
            "authors": [
                {
                    "first": "K",
                    "middle": [
                        "P P C"
                    ],
                    "last": "Reshma Pise",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF19": {
            "ref_id": "b19",
            "title": "An Efficient CNN Model for COVID-19 Disease Detection Based on X-Ray Image",
            "authors": [
                {
                    "first": "Reshi",
                    "middle": [],
                    "last": "Ahmad",
                    "suffix": ""
                },
                {
                    "first": "Aijaz",
                    "middle": [],
                    "last": "",
                    "suffix": ""
                }
            ],
            "year": 2021,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {
                "DOI": [
                    "10.1155/2021/6621607"
                ]
            }
        },
        "BIBREF20": {
            "ref_id": "b20",
            "title": "Diagnosis of vertebral column pathologies using concatenated resampling with machine learning algorithms",
            "authors": [
                {
                    "first": "Reshi",
                    "middle": [],
                    "last": "Ahmad",
                    "suffix": ""
                },
                {
                    "first": "Aijaz",
                    "middle": [],
                    "last": "",
                    "suffix": ""
                }
            ],
            "year": 2021,
            "venue": "PeerJ Computer",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {
                "DOI": [
                    "10.7717/peerj-cs.547"
                ]
            }
        },
        "BIBREF21": {
            "ref_id": "b21",
            "title": "Concurrent outbreaks of dengue, chikungunyaand zika virus infections-an unprecedented epidemic wave of mosquito-borne viruses in the pacific",
            "authors": [
                {
                    "first": "A",
                    "middle": [],
                    "last": "Roth",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Mercier",
                    "suffix": ""
                },
                {
                    "first": "C",
                    "middle": [],
                    "last": "Lepers",
                    "suffix": ""
                },
                {
                    "first": "D",
                    "middle": [],
                    "last": "Hoy",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Duituturaga",
                    "suffix": ""
                },
                {
                    "first": "E",
                    "middle": [],
                    "last": "Benyon",
                    "suffix": ""
                },
                {
                    "first": "L",
                    "middle": [],
                    "last": "Guillaumot",
                    "suffix": ""
                },
                {
                    "first": "Y",
                    "middle": [],
                    "last": "Souares",
                    "suffix": ""
                }
            ],
            "year": 2012,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF22": {
            "ref_id": "b22",
            "title": "Cuatepotzo-Jim\u00b4enez, Mosquito larva classification method based on convolutional neural networks",
            "authors": [
                {
                    "first": "A",
                    "middle": [],
                    "last": "Sanchez-Ortiz",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Fierro-Radilla",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Arista-Jalife",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Cedillo-Hernandez",
                    "suffix": ""
                },
                {
                    "first": "M",
                    "middle": [],
                    "last": "Nakano-Miyatake",
                    "suffix": ""
                },
                {
                    "first": "D",
                    "middle": [],
                    "last": "Robles-Camarillo",
                    "suffix": ""
                }
            ],
            "year": 2017,
            "venue": "2017 International Conference on Electronics",
            "volume": "",
            "issn": "",
            "pages": "1--6",
            "other_ids": {}
        },
        "BIBREF23": {
            "ref_id": "b23",
            "title": "A survey on image data augmentation for deep learning",
            "authors": [
                {
                    "first": "C",
                    "middle": [],
                    "last": "Shorten",
                    "suffix": ""
                },
                {
                    "first": "T",
                    "middle": [
                        "M"
                    ],
                    "last": "Khoshgoftaar",
                    "suffix": ""
                }
            ],
            "year": 2019,
            "venue": "J. Big Data",
            "volume": "6",
            "issn": "1",
            "pages": "1--48",
            "other_ids": {}
        },
        "BIBREF24": {
            "ref_id": "b24",
            "title": "Very deep convolutional networks for large-scale image recognition",
            "authors": [
                {
                    "first": "K",
                    "middle": [],
                    "last": "Simonyan",
                    "suffix": ""
                },
                {
                    "first": "A",
                    "middle": [],
                    "last": "Zisserman",
                    "suffix": ""
                }
            ],
            "year": null,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {
                "arXiv": [
                    "arXiv:1409.1556"
                ]
            }
        },
        "BIBREF25": {
            "ref_id": "b25",
            "title": "Parallel large scale feature selection for logistic regression",
            "authors": [
                {
                    "first": "S",
                    "middle": [],
                    "last": "Singh",
                    "suffix": ""
                },
                {
                    "first": "J",
                    "middle": [],
                    "last": "Kubica",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Larsen",
                    "suffix": ""
                },
                {
                    "first": "D",
                    "middle": [],
                    "last": "Sorokina",
                    "suffix": ""
                }
            ],
            "year": 2009,
            "venue": "Proceedings of the 2009 SIAMinternational conference on data mining",
            "volume": "",
            "issn": "",
            "pages": "1172--1183",
            "other_ids": {}
        },
        "BIBREF26": {
            "ref_id": "b26",
            "title": "Dengue fever information from Taiwan cdc",
            "authors": [],
            "year": 2021,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF27": {
            "ref_id": "b27",
            "title": "Efficientnet, Rethinking model scaling for convolutional neural networks",
            "authors": [
                {
                    "first": "M",
                    "middle": [],
                    "last": "Tan",
                    "suffix": ""
                },
                {
                    "first": "Q",
                    "middle": [],
                    "last": "Le",
                    "suffix": ""
                }
            ],
            "year": 2019,
            "venue": "International Conference on Machine Learning",
            "volume": "",
            "issn": "",
            "pages": "6105--6114",
            "other_ids": {}
        },
        "BIBREF28": {
            "ref_id": "b28",
            "title": "Detecting affect states using vgg16, resnet50 and se-resnet50 networks",
            "authors": [
                {
                    "first": "D",
                    "middle": [],
                    "last": "Theckedath",
                    "suffix": ""
                },
                {
                    "first": "R",
                    "middle": [],
                    "last": "Sedamkar",
                    "suffix": ""
                }
            ],
            "year": 2020,
            "venue": "SN Computer Sci",
            "volume": "1",
            "issn": "2",
            "pages": "1--7",
            "other_ids": {}
        },
        "BIBREF29": {
            "ref_id": "b29",
            "title": "Hemocytome: deep sequencing analysis of mosquito blood cellsin Indian malarial vector anopheles stephensi",
            "authors": [
                {
                    "first": "T",
                    "middle": [],
                    "last": "Thomas",
                    "suffix": ""
                },
                {
                    "first": "T",
                    "middle": [
                        "D"
                    ],
                    "last": "De",
                    "suffix": ""
                },
                {
                    "first": "P",
                    "middle": [],
                    "last": "Sharma",
                    "suffix": ""
                },
                {
                    "first": "S",
                    "middle": [],
                    "last": "Lata",
                    "suffix": ""
                },
                {
                    "first": "P",
                    "middle": [],
                    "last": "Saraswat",
                    "suffix": ""
                },
                {
                    "first": "K",
                    "middle": [
                        "C"
                    ],
                    "last": "Pandey",
                    "suffix": ""
                },
                {
                    "first": "R",
                    "middle": [],
                    "last": "Dixit",
                    "suffix": ""
                }
            ],
            "year": 2016,
            "venue": "Gene",
            "volume": "585",
            "issn": "2",
            "pages": "177--190",
            "other_ids": {}
        },
        "BIBREF30": {
            "ref_id": "b30",
            "title": "Global strategy for dengue prevention and control",
            "authors": [
                {
                    "first": "W",
                    "middle": [
                        "H"
                    ],
                    "last": "Organization",
                    "suffix": ""
                }
            ],
            "year": 2012,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF31": {
            "ref_id": "b31",
            "title": "Vector-borne diseases",
            "authors": [
                {
                    "first": "W",
                    "middle": [
                        "H"
                    ],
                    "last": "Organization",
                    "suffix": ""
                }
            ],
            "year": 2021,
            "venue": "",
            "volume": "",
            "issn": "",
            "pages": "",
            "other_ids": {}
        },
        "BIBREF32": {
            "ref_id": "b32",
            "title": "A direct method of nonparametric measurement selection",
            "authors": [
                {
                    "first": "A",
                    "middle": [
                        "W"
                    ],
                    "last": "Whitney",
                    "suffix": ""
                }
            ],
            "year": 1971,
            "venue": "IEEE Trans. Comput",
            "volume": "100",
            "issn": "9",
            "pages": "1100--1103",
            "other_ids": {}
        }
    },
    "ref_entries": {
        "FIGREF0": {
            "text": "Sample image before and after applying sharp filter.",
            "latex": null,
            "type": "figure"
        },
        "FIGREF1": {
            "text": "Identity mapping function in ResNet-50.",
            "latex": null,
            "type": "figure"
        },
        "FIGREF4": {
            "text": "RoIs from an image.",
            "latex": null,
            "type": "figure"
        },
        "FIGREF5": {
            "text": "Proposed methodology diagram.",
            "latex": null,
            "type": "figure"
        },
        "FIGREF6": {
            "text": "Training and testing accuracy loss for CNNs with RIFS approach.",
            "latex": null,
            "type": "figure"
        },
        "FIGREF7": {
            "text": "Accuracy comparison between all approaches.",
            "latex": null,
            "type": "figure"
        },
        "FIGREF8": {
            "text": "Study(Park et al., 2020) accuracy and loss.",
            "latex": null,
            "type": "figure"
        },
        "TABREF2": {
            "text": "Random splitting of training and testing.Fig. 1. Sample of dataset.",
            "latex": null,
            "type": "table"
        },
        "TABREF3": {
            "text": "Data augmentation.Fig. 2. Sharp filter.",
            "latex": null,
            "type": "table"
        },
        "TABREF4": {
            "text": "\u00bc P 1\u00c21 \u00c1 \u00c1 \u00c1 P 1\u00c2mNow, the final features set for learning models from the RIFS approach can be defined as:RIFS features \u00bc RoI 1\u00c21 \u00c1 \u00c1 \u00c1 RoI 1\u00c2y",
            "latex": null,
            "type": "table"
        },
        "TABREF5": {
            "text": ".",
            "latex": null,
            "type": "table"
        },
        "TABREF6": {
            "text": "Training data size after data augmentation.",
            "latex": null,
            "type": "table"
        },
        "TABREF7": {
            "text": "Performance of machine learning models on the original dataset.",
            "latex": null,
            "type": "table"
        },
        "TABREF9": {
            "text": "Performance of machine learning models after applying ROI extraction technique. Confusion matrix for all machine learning models after applying ROI extraction technique.",
            "latex": null,
            "type": "table"
        },
        "TABREF10": {
            "text": "Performance of CNN variant after applying ROI extraction technique.",
            "latex": null,
            "type": "table"
        },
        "TABREF11": {
            "text": "Performance of machine learning models after applying RIFS techniques.",
            "latex": null,
            "type": "table"
        },
        "TABREF12": {
            "text": "Performance of CNN variant after applying RIFS techniques.Table 18Confusion matrix for all CNN variants after applying RIFS techniques.",
            "latex": null,
            "type": "table"
        },
        "TABREF13": {
            "text": "Comparison results with prior studies. Comparison results in confusion matrix with prior studies.Fig. 10. Study (Akter et al., 2020) accuracy and loss.",
            "latex": null,
            "type": "table"
        },
        "TABREF14": {
            "text": "Training and testing time between our proposed approach and CNN variants.",
            "latex": null,
            "type": "table"
        }
    },
    "back_matter": [
        {
            "text": "This research was supported by the Florida Center for Advanced Analytic and Data Science funded by Ernesto. Net (under the Algorithms for Good Grant). The authors extend their appreciation to the Deanship of Scientific Research at King Saud University for supporting this research work through research group no. RG-1441-455.",
            "cite_spans": [],
            "ref_spans": [],
            "section": "Acknowledgement"
        }
    ]
}